{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter10. 케라스를 사용한 인공 신경망 소개",
      "provenance": [],
      "collapsed_sections": [
        "VTxCrauoYExE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpiy9pM7UI_A"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTxCrauoYExE"
      },
      "source": [
        "#10.1 생물학적 뉴런에서 인공 뉴런까지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaNm8dCzYEmy"
      },
      "source": [
        "##10.1.1 생물학적 뉴런\n",
        "\n",
        "아하 뉴런은 이렇게 구성되어 있구나!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTU9Gjg1YEdY"
      },
      "source": [
        "##10.1.2 뉴런을 사용한 논리 연산\n",
        "\n",
        "복잡한 논리 표현식을 계산하기 위해 네트워크들을 연결하면 된다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lbIgr_hYETX"
      },
      "source": [
        "##10.1.3 퍼셉트론\n",
        "\n",
        "퍼셉트론은 층이 하나뿐인 TLU로 구성됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO51DNiDxz_j"
      },
      "source": [
        "###TLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fuX2Tyunzm"
      },
      "source": [
        "![TLU그림.PNG](data:image/png;base64,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)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ5iBiQ7vco_"
      },
      "source": [
        "TLU에서 가장 널리 사용되는 계단 함수 : **헤비사이드 계단 함수**\n",
        "\n",
        "- $\n",
        "heaviside(z) = \\begin{cases}0 & z < 0 \\text{일 때} \\\\\n",
        "1 & z \\ge 0 \\text{일 때}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "- $\n",
        "sgn(z) = \\begin{cases}-1 & z < 0 \\text{일 때}\\\\\n",
        "0 & z = 0 \\text{일 때}\\\\\n",
        "1 & z > 0 \\text{일 때}\n",
        "\\end{cases}\n",
        "$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7nxRABcwSjS"
      },
      "source": [
        "**완전 연결 층 (밀집 층)**\n",
        "\n",
        "- 한 층에 있는 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있는 경우\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8yhSNwvwerF"
      },
      "source": [
        "퍼셉트론의 **입력 뉴런**에 입력을 넣고, **편향** 특성을 더해서 출력으로 보낸다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZA1k3VswsM0"
      },
      "source": [
        "**완전 연결 층의 출력 계산**\n",
        "\n",
        "$h_{\\mathbf{X}, \\mathbf{b}}(\\mathbf{X}) = \\phi(\\mathbf{XW} + \\mathbf{b})$\n",
        "\n",
        "- $\\mathbf{X}$ : 입력특성의 행렬..\n",
        "- $\\mathbf{W}$ : 편향 뉴런을 제외한 모든 연결 가중치를 포함한 행렬..\n",
        "    - 행 : 입력 뉴런\n",
        "    - 열 : 출력층의 인공 뉴런\n",
        "- $\\mathbf{b}$ : 편향 뉴런과 인공 뉴런 사이의 모든 연결 가중치..\n",
        "- $\\phi$ : **활성화 함수**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFLGU8aEx3Z1"
      },
      "source": [
        "###퍼셉트론의 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPDhERU7x7Ri"
      },
      "source": [
        "**헤브의 규칙**에서 영감을 받음..\n",
        "\n",
        "- 두 뉴런이 동시에 활성화될 때마다 이들 사이의 연결 가중치가 증가하는 경향이 있다..\n",
        "- 퍼셉트론은 네트워크가 예측할 때 만드는 오차를 반영하도록 조금 변형된 규칙을 사용하여 훈련\n",
        "- **퍼셉트론의 학습 규칙은 오차가 감소되도록 연결을 강화시키는 것이다..**\n",
        "    - 잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 연결된 가중치를 강화시킨다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTUOqGbdyfMH"
      },
      "source": [
        "**퍼셉트론 학습 규칙**\n",
        "\n",
        "$\n",
        "w_{i, j}^{\\text{(next step)}} = w_{i, j} + \\eta(y_j - \\hat{y}_j)x_i\n",
        "$\n",
        "\n",
        "- 다음 가중치 = 현재 가중치 + (학습률)*(타깃 - 예측)*(입력)\n",
        "- $w_{i, j}$ : $i$번 째 입력 뉴런과 $j$번 째 출력 뉴런 사이의 가중치\n",
        "- $x_i$ : 현재 훈련 샘플의 $i$번째 뉴런의 입력값\n",
        "- $\\hat{y}_j$ : $j$번째 출력 뉴런의 출력값\n",
        "- $y_j$ : $j$번째 출력 뉴런의 타깃\n",
        "- $\\eta$ : 학습률"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5cyvtsEzkXE"
      },
      "source": [
        "**퍼셉트론 수렴 이론**\n",
        "\n",
        "- 퍼셉트론 하나 가지고는 복잡한 패턴 학습 불가능\n",
        "- 훈련 샘플이 선형적으로 구분될 수 있다면 퍼셉트론이 정답에 수렴한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_thFWytz-0K"
      },
      "source": [
        "**단층퍼셉트론의 한계**\n",
        "\n",
        "- XOR게이트와 같은 간단한 문제를 못 푼다..\n",
        "- **다층 퍼셉트론(MLP)**로 해결 할 수 있다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_SHNu7aYEJn"
      },
      "source": [
        "##10.1.4 다층 퍼셉트론과 역전파"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Ssy6B31uOe"
      },
      "source": [
        "###다층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlOscgLI06Hn"
      },
      "source": [
        "![MLP그림.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1e-vtHS1Pma"
      },
      "source": [
        "**다층 퍼셉트론** = **입력층** + **하나이상의 은닉층** + **출력층**\n",
        "\n",
        "은닉층을 여러개 쌓아올린 인공 신경망을 **심층 신경망(DNN)**이라고 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEBjJJoc1uY9"
      },
      "source": [
        "###역전파\n",
        "\n",
        "- 대강 느낌은 정방향으로 가면서 예측하고, 역방향으로 오면서 가중치와 편향을 바꾼다..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQmM66vq2POl"
      },
      "source": [
        "**역전파 알고리즘**\n",
        "\n",
        "1. 하나의 미니배치씩 진행하여 전체 훈련 세트를 처리하는 과정(각 반복이 **에포크**)\n",
        "\n",
        "2. 각 미니배치를 입력층으로 전달해서 모든 뉴런의 출력을 계산함..\n",
        "    - **정방향 계산**\n",
        "    - 출력층의 출력을 계산할 때까지.. (예측 과정과 동일)\n",
        "    - **역방향 계산을 위해 중간 계산값을 모두 저장**\n",
        "\n",
        "3. 알고리즘이 네트워크의 출력 오차를 측정\n",
        "4. 각 출력 연결이 이 오차에 기여하는 정도를 계산\n",
        "    - **연쇄법칙**(Chain Rule) 사용..\n",
        "    - **역방향 계산**\n",
        "    - 입력층에 도달할 때까지 오차 그레이디언트를 거꾸로 전파..\n",
        "    - 최종적으로 모든 연결 가중치에 대한 오차 그레이디언트를 계산 가능..\n",
        "\n",
        "5. 오차 그레이디언트를 사용해서 네트워크에 있는 모든 연결 가중치를 수정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4piP7dw3s98"
      },
      "source": [
        "**정리**\n",
        "\n",
        "- 정방향으로 가면서 중간 계산값을 모두 저장하면서 예측을 만듦\n",
        "- 예측이 생겼으니 오차가 있음\n",
        "- 역방향으로 각 연결이 그 오차에 얼만큼 기여했는지 계산해 나감..(연쇄법칙)\n",
        "- 오차가 감소하도록 가중치 조정.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA6zY10G39FC"
      },
      "source": [
        "###활성화 함수\n",
        "\n",
        "- 대깨 비선형함수.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dI02ykn4BhM"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def derivative(f, z, eps=0.000001):\n",
        "    return (f(z + eps) - f(z - eps))/(2 * eps)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "ENWbrHaV4HK_",
        "outputId": "cccbb864-ab24-4b70-9ed7-3e8eca2c852f"
      },
      "source": [
        "z = np.linspace(-5, 5, 200)\n",
        "\n",
        "plt.figure(figsize=(11,4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
        "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
        "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
        "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"center right\", fontsize=14)\n",
        "plt.title(\"Activation functions\", fontsize=14)\n",
        "plt.axis([-5, 5, -1.2, 1.2])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\n",
        "plt.plot(0, 0, \"ro\", markersize=5)\n",
        "plt.plot(0, 0, \"rx\", markersize=10)\n",
        "plt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
        "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
        "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
        "plt.grid(True)\n",
        "plt.title(\"Derivatives\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.2, 1.2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYcv48W0YEAc"
      },
      "source": [
        "##10.1.5 회귀를 위한 다층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pDFZm5f4b9R"
      },
      "source": [
        "- **출력 층의 뉴런 수 = 예측해야 하는 값의 수**\n",
        "\n",
        "- 출력층에서 활성화 함수로 범위 조정 가능\n",
        "\n",
        "    - ex) ReLU 함수를 사용해서 출력을 항상 양수로..\n",
        "\n",
        "- 손실함수는 보통 RMSE, 이상치가 많다면 MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIn6K0umYD22"
      },
      "source": [
        "##10.1.6 분류를 위한 다층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jnnv4kD47Yu"
      },
      "source": [
        "원하는 분류 방법에 따라서 구조가 조금씩 다르다!\n",
        "\n",
        "- 이진분류\n",
        "    - 출력층 1개에 시그모이드 활성화 함수 사용..\n",
        "- 다중 레이블 분류\n",
        "    - 분류해야하는 가짓수 만큼 출력뉴런을 만듦..\n",
        "        - ex) 스팸 + 긴급한 메일 두개를 분류 -> 출력 뉴런 2개 필요\n",
        "    - 시그모이드 활성화 함수\n",
        "- 다중분류\n",
        "    - 출력 뉴런을 클래스마다 하나씩 만듦..\n",
        "    - 소프트맥스를 활성화 함수로 사용.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj11IeBk5POc"
      },
      "source": [
        "![다중분류.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyIwdJRhYDtk"
      },
      "source": [
        "#10.2 케라스로 다층 퍼셉트론 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVHqZuusYDjT"
      },
      "source": [
        "##10.2.1 텐서플로 2 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WicGfq0pPYm9",
        "outputId": "95b4e064-d183-44e4-a2e6-8cee46dab4b9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cGvv3r-0PrUU",
        "outputId": "0aeca9fd-b2bb-4a23-bcb4-ed60ae97c611"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NP4hZQbYDZg"
      },
      "source": [
        "##10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9L-ucI0YDRB"
      },
      "source": [
        "###케라스를 사용하여 데이터셋 적재하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9D70lfDPvrT",
        "outputId": "fcd534bd-53c5-45de-bb89-795f22212856"
      },
      "source": [
        "#데이터 불러오기//\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exj_p-XSP7j1",
        "outputId": "ac34372d-c434-4aca-e9f9-3300cc351a9f"
      },
      "source": [
        "print(X_train_full.shape)\n",
        "\n",
        "#데이터 타입이 0~255의 정수형..\n",
        "print(X_train_full.dtype)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFHtQxy8QHYJ"
      },
      "source": [
        "#검증세트 분리하고 스케일링까지..\n",
        "\n",
        "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOpHVCirQgXT"
      },
      "source": [
        "#클래스 이름 준비..\n",
        "\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UBAc1k5OQsfX",
        "outputId": "b16b9456-4f81-42db-f5e9-5aff1272e231"
      },
      "source": [
        "class_names[y_train[0]]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5zbybtUYDIN"
      },
      "source": [
        "###시퀀셜 API를 사용하여 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWZe6dP4RguU"
      },
      "source": [
        "층을 하나씩 추가하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24sY_apuRCAw"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))        #입력모양 명시..\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\"))       #1번째 은닉층\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))       #2번째 은닉층\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))     #다중분류(10개의 클래스)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf-OOE8yRjiv"
      },
      "source": [
        "Sequential 모델을 만들때 층의 리스트를 전달하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcrJpMgSRnyp"
      },
      "source": [
        "#위의 층과 순서 같음..\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCn7imUySOsn"
      },
      "source": [
        "모델의 요약본을 보여주는 summary()메서드\n",
        "\n",
        "- Dense층은 파라미터가 많다.. -> **유연성**을 가지지만 **과대적합 위험**도 있다.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fS8aynVSHQ_",
        "outputId": "1c2932f4-8a6f-49e2-915d-00e8384468ba"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGriYqi5SinL",
        "outputId": "7c4a4d02-93bf-4a97-ae34-2afee8e0edfc"
      },
      "source": [
        "#모든 층 확인..\n",
        "model.layers"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.Flatten at 0x7f1e8a0f7890>,\n",
              " <keras.layers.core.Dense at 0x7f1e8a0f7a50>,\n",
              " <keras.layers.core.Dense at 0x7f1e8a10c090>,\n",
              " <keras.layers.core.Dense at 0x7f1e8a10c350>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0PCP9ErQSnHr",
        "outputId": "14f3e766-249b-48f1-abdb-edb065c267ff"
      },
      "source": [
        "#층을 인덱싱으로 가져올 수도 있다..\n",
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dense_3'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWJPSUiXSuFD",
        "outputId": "3fee0376-f9ef-44a5-b4a9-74e568c4f19d"
      },
      "source": [
        "#층을 이름으로 가져오기..\n",
        "model.get_layer('dense_3') is hidden1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjDf0AkaTCJM",
        "outputId": "10782963-54fa-44ac-8add-1f320979b577"
      },
      "source": [
        "#파라미터는 get_weights()와 set_weights()를 사용해서 접근 가능\n",
        "\n",
        "weights, biases = hidden1.get_weights()\n",
        "\n",
        "print(weights)\n",
        "print(weights.shape)\n",
        "print(biases)\n",
        "print(biases.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.02553563  0.05914272 -0.06740021 ...  0.01845283 -0.00180461\n",
            "   0.01201852]\n",
            " [-0.04342228 -0.06242894 -0.05614512 ... -0.07350495 -0.06379109\n",
            "   0.01146454]\n",
            " [ 0.01683434  0.03777402  0.02653033 ...  0.05587855 -0.0707761\n",
            "   0.01198045]\n",
            " ...\n",
            " [ 0.0526699   0.00332218  0.01839976 ...  0.02379081  0.0103582\n",
            "  -0.02309121]\n",
            " [ 0.05391356 -0.02035915  0.0312015  ... -0.04326656 -0.06837778\n",
            "   0.01828874]\n",
            " [-0.0479302  -0.04359042 -0.0479023  ...  0.03882667 -0.01999313\n",
            "   0.02906266]]\n",
            "(784, 300)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlmYDbOPYC-F"
      },
      "source": [
        "###모델 컴파일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVDUg7vgTec8"
      },
      "source": [
        "손실함수, 옵티마이저, 평가지표를 지정하는 단계.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8cem_ND6b7v"
      },
      "source": [
        "손실함수\n",
        "\n",
        "- 레이블이 0~9 이면 (즉, 원핫인코딩 안되어있을 경우) \"sparse_categorical_crossentropy\" 손실 사용\n",
        "- 레이블이 원핫인코딩 되어있으면 \"categorical_crossentropy\" 손실 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpRCPx1m6xmM"
      },
      "source": [
        "옵티마이저\n",
        "\n",
        "- \"sgd\"로 지정 시 기본 확률적 경사 하강법을 사용한다는 의미..\n",
        "- 즉, 역전파 알고리즘 수행한다는 말.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSePR4lQTUI4"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWN11MzkYC3b"
      },
      "source": [
        "###모델 훈련과 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw0MV9fZ7D9q"
      },
      "source": [
        "에포크가 끝날 때 마다 검증 세트를 사용해서 손실과 추가적인 측정 지표를 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kfek5RO7Lkr"
      },
      "source": [
        "훈련 세트가 클래스 별로 편중되어 있다면 fit()메서드 호출 시 class_weight 매개변수를 지정\n",
        "\n",
        "- 적게 등장하는 클래스는 높은 가중치, 많이 등장하는 클래스는 낮은 가중치..\n",
        "- 샘플별로 가중치 부여하려면 sample_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY_bxirgTqHh",
        "outputId": "347511b8-2fed-4c74-cf4f-22a1b7c9dc7b"
      },
      "source": [
        "#3분 소요\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7281 - accuracy: 0.7602 - val_loss: 0.5511 - val_accuracy: 0.8048\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4945 - accuracy: 0.8274 - val_loss: 0.4667 - val_accuracy: 0.8406\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4484 - accuracy: 0.8437 - val_loss: 0.4412 - val_accuracy: 0.8446\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4214 - accuracy: 0.8508 - val_loss: 0.3996 - val_accuracy: 0.8610\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4016 - accuracy: 0.8593 - val_loss: 0.3948 - val_accuracy: 0.8650\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3850 - accuracy: 0.8651 - val_loss: 0.3919 - val_accuracy: 0.8594\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3715 - accuracy: 0.8688 - val_loss: 0.3809 - val_accuracy: 0.8698\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3587 - accuracy: 0.8734 - val_loss: 0.3554 - val_accuracy: 0.8770\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3483 - accuracy: 0.8760 - val_loss: 0.3453 - val_accuracy: 0.8790\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3372 - accuracy: 0.8799 - val_loss: 0.3640 - val_accuracy: 0.8666\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3291 - accuracy: 0.8827 - val_loss: 0.3452 - val_accuracy: 0.8780\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3212 - accuracy: 0.8857 - val_loss: 0.3286 - val_accuracy: 0.8868\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3136 - accuracy: 0.8876 - val_loss: 0.3321 - val_accuracy: 0.8856\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3059 - accuracy: 0.8914 - val_loss: 0.3189 - val_accuracy: 0.8884\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2995 - accuracy: 0.8937 - val_loss: 0.3454 - val_accuracy: 0.8756\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2933 - accuracy: 0.8954 - val_loss: 0.3110 - val_accuracy: 0.8918\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2876 - accuracy: 0.8972 - val_loss: 0.3134 - val_accuracy: 0.8916\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2816 - accuracy: 0.8988 - val_loss: 0.3060 - val_accuracy: 0.8924\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2763 - accuracy: 0.9009 - val_loss: 0.3056 - val_accuracy: 0.8946\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2710 - accuracy: 0.9025 - val_loss: 0.3240 - val_accuracy: 0.8820\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2656 - accuracy: 0.9046 - val_loss: 0.3114 - val_accuracy: 0.8916\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2608 - accuracy: 0.9058 - val_loss: 0.3084 - val_accuracy: 0.8914\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2557 - accuracy: 0.9086 - val_loss: 0.3090 - val_accuracy: 0.8906\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2519 - accuracy: 0.9100 - val_loss: 0.3050 - val_accuracy: 0.8926\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2473 - accuracy: 0.9107 - val_loss: 0.3004 - val_accuracy: 0.8968\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2440 - accuracy: 0.9120 - val_loss: 0.3052 - val_accuracy: 0.8914\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2390 - accuracy: 0.9148 - val_loss: 0.3102 - val_accuracy: 0.8888\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2343 - accuracy: 0.9164 - val_loss: 0.2919 - val_accuracy: 0.8964\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2316 - accuracy: 0.9173 - val_loss: 0.3015 - val_accuracy: 0.8920\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2277 - accuracy: 0.9182 - val_loss: 0.2906 - val_accuracy: 0.8924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "jSaTUVIbUeKb",
        "outputId": "3e9ecc4d-f60e-41f7-9ca1-7aa39d2c0c2f"
      },
      "source": [
        "#History 객체에 훈련파라미터와 에포크 정보가 들어있다..\n",
        "#그걸 그래프로 그림..\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)     #수직축의 범위를 0~1로 지정\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwlotTft7jKV"
      },
      "source": [
        "**분석**\n",
        "\n",
        "- 훈련 정확도와 검증 정확도 꾸준히 증가\n",
        "- 훈련 손실과 검증 손실 감소..\n",
        "- 훈련 곡선을 볼 때 왼쪽으로 에포크의 절반만큼 이동해서 봐라.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEKfKyD-70x-"
      },
      "source": [
        "**모델 성능이 만족스럽지 않다면..?**\n",
        "\n",
        "1. 학습률 확인\n",
        "2. 그래도 안 좋으면 다른 파라미터\n",
        "3. 다시 학습률.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD0tpqITVDNg",
        "outputId": "b2cf03e6-db6b-4916-b55e-d3ae1d1f54c9"
      },
      "source": [
        "#검증세트보다 조금 낮은 성능이 나오는게 일반적..\n",
        "\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 65.5085 - accuracy: 0.8445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[65.50848388671875, 0.8445000052452087]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKEjfc9cYCwm"
      },
      "source": [
        "###모델을 사용해 예측을 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fScT0SPgVQVP",
        "outputId": "db03705f-f6bd-4e87-a730-8fbd4b16100d"
      },
      "source": [
        "#새로운 데이터에 대해서 예측을 한다..\n",
        "#각 클래스일 확률을 반환..\n",
        "\n",
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zUL6T-vDVjf2",
        "outputId": "91c1ece0-7eb1-492a-a96b-d517987a979d"
      },
      "source": [
        "#얘는 안되나바.. predict_classes가 안되나바..\n",
        "\"\"\"\n",
        "y_pred = model.predict_classes(X_new)\n",
        "print(y_pred)\n",
        "print(np.array(class_names)[y_pred])\n",
        "\"\"\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ny_pred = model.predict_classes(X_new)\\nprint(y_pred)\\nprint(np.array(class_names)[y_pred])\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq0pZHgwV9Aj",
        "outputId": "21f5b6a0-6b56-43e8-fe90-44e428037381"
      },
      "source": [
        "y_new = y_test[:3]\n",
        "y_new"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyKGttjdYCkn"
      },
      "source": [
        "##10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLL7PfdqWC7e"
      },
      "source": [
        "화귀에서 달라진 점\n",
        "\n",
        "- 출력층이 활성화 함수가 없는 하나의 뉴런이다\n",
        "- 손실함수로 RMSE를 사용한다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzfpXEUnWaGW"
      },
      "source": [
        "캘리포니아 주택 가격 데이터셋으로 시도하겠다 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_LNVrX6WX91",
        "outputId": "e2862397-1899-4ec0-cebd-97b73392ef24"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "#훈련, 검증, 테스트세트 분리..\n",
        "X_train_full , X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "#스케일링까지..\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoALZTmPXn_1",
        "outputId": "a413bd41-176b-4f19-d0a1-5a56be8ba321"
      },
      "source": [
        "#11610개의 샘플, 8개의 특성\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11610, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwZ6AEu0WK1A",
        "outputId": "f3b68925-b4a6-4e53-8496-bc875c08059a"
      },
      "source": [
        "#회귀라서 출력 뉴런 1개\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),        #8개의 특성이 입력된다..\n",
        "        keras.layers.Dense(1)       #출력층, 원하는 값의 수만큼 뉴런 생성\n",
        "])\n",
        "\n",
        "#회귀라서 손실도 RMSE\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "\n",
        "X_new = X_test[:3]      #새로운 샘플이라고 생각..\n",
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.9054 - val_loss: 0.9595\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.8106 - val_loss: 0.5122\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4343 - val_loss: 0.4593\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4139 - val_loss: 0.4451\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4034 - val_loss: 0.4298\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3854 - val_loss: 0.4214\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3831 - val_loss: 0.4148\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.4101\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3933 - val_loss: 0.4214\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3976\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3653 - val_loss: 0.4037\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3552 - val_loss: 0.3877\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3575 - val_loss: 0.3965\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.3800\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3471 - val_loss: 0.3775\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3519 - val_loss: 0.3791\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3426 - val_loss: 0.4149\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3881\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3387 - val_loss: 0.3768\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3378 - val_loss: 0.3668\n",
            "162/162 [==============================] - 0s 907us/step - loss: 0.3567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMUW_6TZYfWe",
        "outputId": "63e0bb63-6df3-4518-c199-ec91d2c056f7"
      },
      "source": [
        "#손실함수 값..\n",
        "\n",
        "mse_test"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35666000843048096"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acnSDgSrYmib",
        "outputId": "65b4786d-7c81-40df-f2fb-1669cf66ceec"
      },
      "source": [
        "#예측 값..\n",
        "\n",
        "y_pred"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.109302 ],\n",
              "       [1.8280717],\n",
              "       [1.3480762]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxz9imRHYChI"
      },
      "source": [
        "##10.2.4 함수형 API를 사용해 복잡한 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq5xSVQFYxW8"
      },
      "source": [
        "입력의 일부 또는 전체가 출력층에 바로 연결됨..\n",
        "\n",
        "- 은닉층을 모두 통과하는 입력은 **복잡한 패턴**을 학습한다\n",
        "- 바로 출력층에 연결되는 입력은 **간단한 규칙**을 학습한다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii3FwZyA8hDP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJaucPc2ZAvG"
      },
      "source": [
        "#입력 지정..\n",
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "\n",
        "#층을 함수라고 생각했을때 input_이 입력이 된다..\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)     \n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "\n",
        "#입력과 은닉층의 결과를 연결하는 연결층..\n",
        "concat = keras.layers.Concatenate()([input_, hidden2])\n",
        "\n",
        "#출력층에 전달..\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "\n",
        "#초기 입력과 최종 출력을 연결해서 모델 생성..\n",
        "model = keras.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Z9L0ZsbjbO",
        "outputId": "2df9d210-a32d-4eb4-be5c-fe113aee1b38"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
            "                                                                 dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            39          concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktd9E7PhcDq-"
      },
      "source": [
        "컴파일하고 훈련해서 예측하기.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7eFR8UXcB3C",
        "outputId": "429cd91d-6117-4267-9b62-8342e2b6e42c"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.9027 - val_loss: 0.9384\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.8092 - val_loss: 0.8185\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7272 - val_loss: 0.7515\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6738 - val_loss: 0.7052\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6324 - val_loss: 0.6664\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6001 - val_loss: 0.6501\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5736 - val_loss: 0.6145\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5529 - val_loss: 0.5976\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5357 - val_loss: 0.5876\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5215 - val_loss: 0.5755\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5104 - val_loss: 0.5548\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5011 - val_loss: 0.5461\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4924 - val_loss: 0.5354\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4854 - val_loss: 0.5298\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4799 - val_loss: 0.5235\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.5212\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4697 - val_loss: 0.5141\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.5203\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4610 - val_loss: 0.5119\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4552 - val_loss: 0.4955\n",
            "162/162 [==============================] - 0s 902us/step - loss: 0.4814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-8ePzUDcNjc"
      },
      "source": [
        "두 경로에 다른 입력 특성을 전달하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXOqB1DX8t5y"
      },
      "source": [
        "![여러개의입력다루기.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgjYh6IscKby"
      },
      "source": [
        "#입력을 따로 지정..\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "\n",
        "#은닉층에는 input_B만 전달\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "\n",
        "#input_A와 은닉층의 결과 합침..\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "#출력층에 전달..\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "\n",
        "#두개의 입력을 구분해서 리스트로 전달..\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBSISALccj8-",
        "outputId": "aa42f367-8d32-4410-b763-71596bceff0d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 30)           930         dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            36          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,176\n",
            "Trainable params: 1,176\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRL3UTUfcyL6"
      },
      "source": [
        "컴파일, 훈련, 예측 할때도 모두 입력을 다르게 해줘야함..\n",
        "\n",
        "- 모델의 입력에 맞도록!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y9xs8ascxwj",
        "outputId": "cb354a4a-e81c-44ac-f985-92186ba5be79"
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "#전체 특성이 8개였음..\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "\n",
        "#새로운 데이터 지정..\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "#훈련(입력을 다르게 넣어줌..)\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
        "\n",
        "#예측할 때도..\n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.0848 - val_loss: 0.9554\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7470 - val_loss: 0.7332\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6456 - val_loss: 0.6793\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6000 - val_loss: 0.6410\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5711 - val_loss: 0.6166\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5510 - val_loss: 0.5998\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5865\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5216 - val_loss: 0.5737\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.5708\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5033 - val_loss: 0.5560\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4965 - val_loss: 0.5511\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4906 - val_loss: 0.5454\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4852 - val_loss: 0.5374\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4804 - val_loss: 0.5421\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4770 - val_loss: 0.5302\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4734 - val_loss: 0.5267\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4705 - val_loss: 0.5266\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4674 - val_loss: 0.5314\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4652 - val_loss: 0.5214\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4624 - val_loss: 0.5135\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTT1S4LYdiQ7",
        "outputId": "9cd25b74-0b64-4817-f0f5-3979292c007d"
      },
      "source": [
        "mse_test"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49466991424560547"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG-egLgodjgl",
        "outputId": "6711eda0-b70e-4595-b970-b50c45438c4e"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5920267],\n",
              "       [1.948524 ],\n",
              "       [1.274003 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9sJ_NGwds1N"
      },
      "source": [
        "보조출력을 추가하기!!\n",
        "\n",
        "- 은닉층의 결과만 따로 출력하고 싶다..\n",
        "- 각 출력은 자신만의 손실 함수가 필요하다..\n",
        "    - 따로 컴파일단계에서 지정해 줘야한다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8fO7Jqhd3BH"
      },
      "source": [
        "#위와 동일..\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "\n",
        "#보조 출력 추가.. 두번째 은닉층의 결과를 받아옴..\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
        "\n",
        "#모델 생성 시 출력에도 추가..\n",
        "model = keras.models.Model(inputs=[input_A, input_B],\n",
        "                           outputs=[output, aux_output])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NHAOuzPd7My"
      },
      "source": [
        "#각 출력을 위한 손실함수를 리스트로 전달..\n",
        "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], \n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-SgAjp8ePGL",
        "outputId": "ca83d8c8-b39a-40a6-a515-9a762eb331b1"
      },
      "source": [
        "#훈련..\n",
        "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.6040 - main_output_loss: 2.4764 - aux_output_loss: 3.7532 - val_loss: 1.3745 - val_main_output_loss: 1.1989 - val_aux_output_loss: 2.9552\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0678 - main_output_loss: 0.9080 - aux_output_loss: 2.5061 - val_loss: 0.9710 - val_main_output_loss: 0.8315 - val_aux_output_loss: 2.2262\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8428 - main_output_loss: 0.7138 - aux_output_loss: 2.0037 - val_loss: 0.8491 - val_main_output_loss: 0.7329 - val_aux_output_loss: 1.8952\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7590 - main_output_loss: 0.6467 - aux_output_loss: 1.7694 - val_loss: 0.7876 - val_main_output_loss: 0.6832 - val_aux_output_loss: 1.7274\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7116 - main_output_loss: 0.6084 - aux_output_loss: 1.6409 - val_loss: 0.7485 - val_main_output_loss: 0.6506 - val_aux_output_loss: 1.6289\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6789 - main_output_loss: 0.5810 - aux_output_loss: 1.5599 - val_loss: 0.7190 - val_main_output_loss: 0.6260 - val_aux_output_loss: 1.5560\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6543 - main_output_loss: 0.5604 - aux_output_loss: 1.4994 - val_loss: 0.6977 - val_main_output_loss: 0.6087 - val_aux_output_loss: 1.4989\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6353 - main_output_loss: 0.5451 - aux_output_loss: 1.4470 - val_loss: 0.6806 - val_main_output_loss: 0.5946 - val_aux_output_loss: 1.4551\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6199 - main_output_loss: 0.5328 - aux_output_loss: 1.4041 - val_loss: 0.6673 - val_main_output_loss: 0.5839 - val_aux_output_loss: 1.4171\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6069 - main_output_loss: 0.5225 - aux_output_loss: 1.3666 - val_loss: 0.6546 - val_main_output_loss: 0.5737 - val_aux_output_loss: 1.3820\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5956 - main_output_loss: 0.5138 - aux_output_loss: 1.3316 - val_loss: 0.6424 - val_main_output_loss: 0.5640 - val_aux_output_loss: 1.3482\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5862 - main_output_loss: 0.5069 - aux_output_loss: 1.2996 - val_loss: 0.6341 - val_main_output_loss: 0.5580 - val_aux_output_loss: 1.3195\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5775 - main_output_loss: 0.5006 - aux_output_loss: 1.2699 - val_loss: 0.6254 - val_main_output_loss: 0.5514 - val_aux_output_loss: 1.2913\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5698 - main_output_loss: 0.4951 - aux_output_loss: 1.2418 - val_loss: 0.6184 - val_main_output_loss: 0.5464 - val_aux_output_loss: 1.2665\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5624 - main_output_loss: 0.4897 - aux_output_loss: 1.2162 - val_loss: 0.6143 - val_main_output_loss: 0.5443 - val_aux_output_loss: 1.2442\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5562 - main_output_loss: 0.4855 - aux_output_loss: 1.1924 - val_loss: 0.6059 - val_main_output_loss: 0.5375 - val_aux_output_loss: 1.2215\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5500 - main_output_loss: 0.4812 - aux_output_loss: 1.1698 - val_loss: 0.5985 - val_main_output_loss: 0.5318 - val_aux_output_loss: 1.1994\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5440 - main_output_loss: 0.4770 - aux_output_loss: 1.1470 - val_loss: 0.5921 - val_main_output_loss: 0.5270 - val_aux_output_loss: 1.1781\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5386 - main_output_loss: 0.4734 - aux_output_loss: 1.1248 - val_loss: 0.5860 - val_main_output_loss: 0.5225 - val_aux_output_loss: 1.1576\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5334 - main_output_loss: 0.4701 - aux_output_loss: 1.1031 - val_loss: 0.5832 - val_main_output_loss: 0.5215 - val_aux_output_loss: 1.1384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQYTS-kHeSk4",
        "outputId": "7c85063a-b08a-437d-e25c-2075d2b65299"
      },
      "source": [
        "#evaluate()메서드 수행 시 개별 손실과 함께 총 손실도 반홛..\n",
        "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
        "\n",
        "#예측도 각 출력에 대한 예측을 반환..\n",
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.5623 - main_output_loss: 0.5016 - aux_output_loss: 1.1089\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1e7c817c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFzwMi9gei13",
        "outputId": "61b24ee8-8a57-4dad-974c-9212d06fa937"
      },
      "source": [
        "print(total_loss, main_loss, aux_loss)\n",
        "print(y_pred_main)\n",
        "print(y_pred_aux)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5623286366462708 0.5015957355499268 1.1089245080947876\n",
            "[[2.6677628]\n",
            " [1.9577506]\n",
            " [1.3149649]]\n",
            "[[2.062422 ]\n",
            " [1.8995578]\n",
            " [1.6353428]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDVRWyISYCQO"
      },
      "source": [
        "##10.2.5 서브클래싱 API로 동적 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDtZifP9ey1B"
      },
      "source": [
        "- 위의 시퀀셜 API, 함수형 API는 모두 선언적이다..\n",
        "- 정적인 그래프이다..\n",
        "- 장점이 많다..\n",
        "    - 저장, 복사, 공유가 쉽다..\n",
        "    - 모델의 구조를 분석하기 쉽다..\n",
        "- 단점이 될 수도 있는데, 좀 딱딱한 느김이다..\n",
        "- 서브클래싱 API를 사용하면 더 자유로워진다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGuR5I7IgxrS"
      },
      "source": [
        "**서브클래싱 API 분석**\n",
        "\n",
        "- 장점\n",
        "    - call()메서드 안에서 어떠한 계산도 사용할 수 있다..\n",
        "- 단점\n",
        "    - 분석이 어렵다..\n",
        "    - 층 간의 연결 정보를 얻기 어렵다.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3beSxn9fGl7"
      },
      "source": [
        "class WideAndDeepModel(keras.Model):\n",
        "    #생성자에서 층 구성..\n",
        "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)  #표준 매개변수를 처리합니다\n",
        "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "        self.main_output = keras.layers.Dense(1)\n",
        "        self.aux_output = keras.layers.Dense(1)\n",
        "\n",
        "    #call메서드에서 수행하려는 연산을 기술..\n",
        "    def call(self, inputs):\n",
        "        input_A, input_B = inputs   #인자로 받은 입력..\n",
        "\n",
        "        #은닉층 구성하고 input_B 특성만 전달..\n",
        "        hidden1 = self.hidden1(input_B)\n",
        "        hidden2 = self.hidden2(hidden_1)\n",
        "\n",
        "        #연결층에서 연결..\n",
        "        concat = keras.layers.concatenate([input_A, hidden2])\n",
        "\n",
        "        #메인과 보조출력 추가..\n",
        "        main_output = self.main_output(concat)\n",
        "        aux_output = self.aux_output(hidden2)\n",
        "        return main_output, aux_output\n",
        "\n",
        "model = WideAndDeepModel()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCnGapLx9fEm"
      },
      "source": [
        "**분석**\n",
        "\n",
        "- 생성자와 call()메서드에서 층 구성과 정방향 계산을 분리했다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVqicIjTYCMl"
      },
      "source": [
        "##10.2.6 모델 저장과 복원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpY8JJ7tg-lM",
        "outputId": "febd3efd-ad79-44ca-8f2c-788def3512b7"
      },
      "source": [
        "#모델 생성..\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#모델 컴파일..\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "#훈련 및 예측..\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.3111 - val_loss: 1.1206\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8388 - val_loss: 0.7353\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6546 - val_loss: 0.6676\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6112 - val_loss: 0.6329\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5821 - val_loss: 0.6090\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5602 - val_loss: 0.5861\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5412 - val_loss: 0.5683\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5535\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5113 - val_loss: 0.5397\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4994 - val_loss: 0.5293\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.5233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpLg7XurjzII"
      },
      "source": [
        "#모델 저장\n",
        "\n",
        "model.save(\"my_keras_model.h5\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxlxpK0Hj3hp"
      },
      "source": [
        "#불러오기\n",
        "\n",
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-04b3v9kDCn",
        "outputId": "c53e9628-0f07-4254-cb09-ec0d3aa8e66d"
      },
      "source": [
        "#가중치 저장 및 불러오기도 가능\n",
        "\n",
        "model.save_weights(\"my_keras_weights.ckpt\")\n",
        "model.load_weights(\"my_keras_weights.ckpt\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1e7c6d3490>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqxLjejjYCJN"
      },
      "source": [
        "##10.2.7 콜백 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noX3hthtkQTK"
      },
      "source": [
        "훈련과정에서 일정한 간격으로 체크포인트를 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6RUJvhHkU99"
      },
      "source": [
        "#모델 생성..\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#모델 컴파일..\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70WeE5hfk79s"
      },
      "source": [
        "체크포인트 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8qYRRa7km9x",
        "outputId": "79920c31-3356-43f5-e5ae-03ba0122da60"
      },
      "source": [
        "#최상의 검증 세트 점수에서만 모델 저장..\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb])\n",
        "\n",
        "#최상의 모델로 롤백\n",
        "model = keras.models.load_model(\"my_keras_model.h5\")\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.7868 - val_loss: 0.9388\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.8075 - val_loss: 0.7791\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6907 - val_loss: 0.7194\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6417 - val_loss: 0.6737\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6433\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5747 - val_loss: 0.6143\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5507 - val_loss: 0.5916\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5318 - val_loss: 0.5773\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5168 - val_loss: 0.5624\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.5475\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.5193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XOXm4GXldRC"
      },
      "source": [
        "**조기종료 콜백 사용**\n",
        "\n",
        "- 에포크의 제한이 없어진다..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLU6j3EQlhNK",
        "outputId": "88f37a3a-9771-4e20-fa80-fca6c6944527"
      },
      "source": [
        "#조기종료 콜백 객체 생성\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "#훈련..\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4946 - val_loss: 0.5410\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4862 - val_loss: 0.5331\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4793 - val_loss: 0.5242\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4734 - val_loss: 0.5187\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4683 - val_loss: 0.5123\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 0.5076\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4599 - val_loss: 0.5040\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4994\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4537 - val_loss: 0.4975\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4509 - val_loss: 0.4911\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4480 - val_loss: 0.4889\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4455 - val_loss: 0.4840\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4848\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4411 - val_loss: 0.4802\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4389 - val_loss: 0.4769\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4369 - val_loss: 0.4741\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4348 - val_loss: 0.4720\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4713\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4676\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4661\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4277 - val_loss: 0.4642\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4626\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4242 - val_loss: 0.4611\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4582\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4214 - val_loss: 0.4564\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4553\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4526\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4167 - val_loss: 0.4513\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4151 - val_loss: 0.4496\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4485\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.4470\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4108 - val_loss: 0.4450\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4095 - val_loss: 0.4440\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.4427\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4068 - val_loss: 0.4409\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4402\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.4387\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 0.4382\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4360\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4341\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4332\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.4316\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3969 - val_loss: 0.4307\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4298\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3946 - val_loss: 0.4283\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3931 - val_loss: 0.4289\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3924 - val_loss: 0.4264\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3913 - val_loss: 0.4252\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.4235\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3889 - val_loss: 0.4227\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3875 - val_loss: 0.4212\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.4201\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3855 - val_loss: 0.4191\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3846 - val_loss: 0.4183\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3836 - val_loss: 0.4169\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3824 - val_loss: 0.4171\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4150\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3806 - val_loss: 0.4141\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4133\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4120\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.4109\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.4099\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3760 - val_loss: 0.4090\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4078\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.4071\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3734 - val_loss: 0.4056\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.4049\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4045\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4038\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3701 - val_loss: 0.4032\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3690 - val_loss: 0.4019\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.4014\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4007\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.3990\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3660 - val_loss: 0.4000\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3654 - val_loss: 0.3971\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3642 - val_loss: 0.3972\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3639 - val_loss: 0.3960\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3627 - val_loss: 0.3949\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3953\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3934\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3608 - val_loss: 0.3925\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3600 - val_loss: 0.3926\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3917\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3586 - val_loss: 0.3910\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3579 - val_loss: 0.3910\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3893\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3895\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3559 - val_loss: 0.3876\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3553 - val_loss: 0.3882\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3543 - val_loss: 0.3866\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3535 - val_loss: 0.3865\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3847\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3856\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3846\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3513 - val_loss: 0.3841\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3508 - val_loss: 0.3826\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3494 - val_loss: 0.3823\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3809\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3484 - val_loss: 0.3816\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acxCxnxXmBTW"
      },
      "source": [
        "사용자 정의 콜백도 만들 수 있다..\n",
        "\n",
        "- 훈련하는 동안 검증손실과 훈련손실의 비율을 출력한다..\n",
        "- 과대적합 방지 용도.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbY01M2VmAU4"
      },
      "source": [
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxDcDo9Smh42",
        "outputId": "1a4800ff-eace-4435-ae1f-7994a233984f"
      },
      "source": [
        "#이렇게 전달 가능..\n",
        "\n",
        "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[val_train_ratio_cb])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3799\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3809\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3461 - val_loss: 0.3801\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3456 - val_loss: 0.3776\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3449 - val_loss: 0.3775\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3773\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3759\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3759\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3743\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.3746\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3409 - val_loss: 0.3736\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3405 - val_loss: 0.3732\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3401 - val_loss: 0.3724\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3396 - val_loss: 0.3714\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3387 - val_loss: 0.3719\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3699\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3377 - val_loss: 0.3707\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3373 - val_loss: 0.3692\n",
            "\n",
            "val/train: 1.09\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3366 - val_loss: 0.3691\n",
            "\n",
            "val/train: 1.10\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3681\n",
            "\n",
            "val/train: 1.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByFPCVFjYCF9"
      },
      "source": [
        "##10.2.8 텐서보드를 사용해 시각화하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAc3thkxYCCj"
      },
      "source": [
        "#10.3 신경망 하이퍼파라미터 튜닝하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuTvj5o_naun"
      },
      "source": [
        "- 신경망이 유연할수록, 트레이드오프로 조정할 하이퍼파라미터가 많다는 단점도 존재한다..\n",
        "\n",
        "- 랜덤서치나 그리드서치를 조진다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZXDewvAn336"
      },
      "source": [
        "build_model()메서드 생성..\n",
        "\n",
        "- 시퀀셜 모델 생성\n",
        "- n_hidden만큼의 은닉층 생성..\n",
        "- 은닉층의 뉴런 수는 n_neurons.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT3_IyGMnrD3"
      },
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    #시퀀셜 모델 생성..\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    \n",
        "    #n_hidden 만큼의 은닉층 추가\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    #옵티마이저 지정..\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6no8HZu7oQrm"
      },
      "source": [
        "#기본 build_model으로 모델 생성..\n",
        "\n",
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Zbk4ysoaHv",
        "outputId": "81402ff3-5d04-4e0c-e052-e656cb367314"
      },
      "source": [
        "#콜백 지정해서 훈련..\n",
        "\n",
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.3301 - val_loss: 0.7528\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6264 - val_loss: 0.6334\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5495 - val_loss: 0.5703\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5038 - val_loss: 0.5401\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4929 - val_loss: 0.5375\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4780 - val_loss: 0.5057\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.5062\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.5115\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4446 - val_loss: 0.4899\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4400 - val_loss: 0.4885\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4782\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4699\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4756\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4625\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4919\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4389 - val_loss: 0.4617\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4617\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4592\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4165 - val_loss: 0.4601\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4297 - val_loss: 0.4524\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4515\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4528\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4482\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4071 - val_loss: 0.4467\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4593\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4396\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4036 - val_loss: 0.4418\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3990 - val_loss: 0.4365\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4352\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4357\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4331\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4317\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4267\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4279\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4232\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.4311\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4226\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4199\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.4210\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4171\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4194\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3934 - val_loss: 0.4178\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.4184\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4134\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3788 - val_loss: 0.4133\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3777 - val_loss: 0.4124\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3754 - val_loss: 0.4167\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3848 - val_loss: 0.4094\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4082\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4064\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3710 - val_loss: 0.4069\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4053\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3694 - val_loss: 0.4049\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.4016\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3676 - val_loss: 0.4028\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.4010\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.4006\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3649 - val_loss: 0.3997\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.3971\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3974\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.3959\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3961\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.3952\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3964\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3940\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3586 - val_loss: 0.3916\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3955\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3576 - val_loss: 0.3917\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3572 - val_loss: 0.3981\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3890\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3554 - val_loss: 0.3894\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3547 - val_loss: 0.3930\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3914\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3926\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3971\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3567 - val_loss: 0.3873\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3833\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3516 - val_loss: 0.3812\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3825\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3548 - val_loss: 0.3819\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3495 - val_loss: 0.3821\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3491 - val_loss: 0.3850\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3496 - val_loss: 0.3849\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3898\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3847\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3563 - val_loss: 0.3804\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3491 - val_loss: 0.3788\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3794\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.3787\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3843\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4611 - val_loss: 0.3797\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3451 - val_loss: 0.3748\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3871\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3832\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3780\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3717\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3724\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3438 - val_loss: 0.3708\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3763\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.3726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e7c38c210>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd_KZ6tkotpE",
        "outputId": "08131e5f-0ac6-4957-e4ed-eb2711c24b9a"
      },
      "source": [
        "#점수 확인..\n",
        "mse_test = keras_reg.score(X_test, y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 917us/step - loss: 0.3687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aOY221RosCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29fc375-0e8e-4f71-8837-879a9d853699"
      },
      "source": [
        "#예측 확인..\n",
        "#보류..\n",
        "\n",
        "y_pred = keras_reg.predict(X_new)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1e7c2f9830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LZUqfZnpTwS",
        "outputId": "dd865d59-6905-47cd-af17-8a23bfe27994"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.0328043, 1.8199148, 1.495131 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ng-Fvo2o307"
      },
      "source": [
        "**랜덤 서치**\n",
        "\n",
        "- 오류 해결을 위한 .tolist(), .rvs(1000).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-3l0XKXo-cA",
        "outputId": "1736f6b7-8114-4348-cdd4-e69955bb82e3"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#탐색할 하이퍼파라미터..\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "#랜덤서치 객체.. cv가 지정되므로 X_valid와 y_valid는 조기종료에만 사용됨..\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs,\n",
        "                                   n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] n_neurons=23, n_hidden=3, learning_rate=0.0277582354248053 ......\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9072 - val_loss: 0.4483\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.5630\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5222\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.4165\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4035\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3814\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3682\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3270 - val_loss: 0.3647\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3256 - val_loss: 0.3888\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3685\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3211 - val_loss: 0.3739\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3114 - val_loss: 0.3612\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3603\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3075 - val_loss: 0.3585\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3461\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3541\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2946 - val_loss: 0.3600\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2956 - val_loss: 0.3382\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2885 - val_loss: 0.3654\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2902 - val_loss: 0.3343\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 0.3396\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2830 - val_loss: 0.3395\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2837 - val_loss: 0.3276\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.3254\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2772 - val_loss: 0.3583\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2790 - val_loss: 0.3622\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2751 - val_loss: 0.3340\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2780 - val_loss: 0.3347\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2756 - val_loss: 0.3244\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2735 - val_loss: 0.3296\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2712 - val_loss: 0.3197\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2711 - val_loss: 0.3445\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.3386\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2678 - val_loss: 0.3305\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2675 - val_loss: 0.3253\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2633 - val_loss: 0.3300\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2626 - val_loss: 0.3365\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2606 - val_loss: 0.3374\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2629 - val_loss: 0.3304\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2625 - val_loss: 0.3287\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2605 - val_loss: 0.3293\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3404\n",
            "[CV]  n_neurons=23, n_hidden=3, learning_rate=0.0277582354248053, total=  18.1s\n",
            "[CV] n_neurons=23, n_hidden=3, learning_rate=0.0277582354248053 ......\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.1s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6567 - val_loss: 0.6572\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6969 - val_loss: 0.5206\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.5093\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.4626\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.4432\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 0.4234\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4113\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.3994\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3934\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.3876\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.3793\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.3651\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3595\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.3588\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3155 - val_loss: 0.3848\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3614\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3534\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3371\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3758\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.3572\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2949 - val_loss: 0.3777\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2935 - val_loss: 0.3349\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2937 - val_loss: 0.3453\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2919 - val_loss: 0.3479\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2912 - val_loss: 0.3466\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.3513\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2869 - val_loss: 0.3248\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.3165\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2837 - val_loss: 0.3220\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2819 - val_loss: 0.3162\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2827 - val_loss: 0.3349\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3316\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2819 - val_loss: 0.3196\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2779 - val_loss: 0.3085\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2726 - val_loss: 0.3567\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2764 - val_loss: 0.3238\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2790 - val_loss: 0.3148\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2760 - val_loss: 0.3190\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2718 - val_loss: 0.3171\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2694 - val_loss: 0.3289\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2661 - val_loss: 0.3428\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2672 - val_loss: 0.3310\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2670 - val_loss: 0.3578\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2699 - val_loss: 0.3099\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.2965\n",
            "[CV]  n_neurons=23, n_hidden=3, learning_rate=0.0277582354248053, total=  19.0s\n",
            "[CV] n_neurons=23, n_hidden=3, learning_rate=0.0277582354248053 ......\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7061 - val_loss: 0.5377\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.4641\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.4350\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.4595\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4209\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4163\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4297\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.3842\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3912\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3847\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.3983\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.3800\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3506\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 0.3720\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.3429\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3516\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3557\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3834\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3917\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3486\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3242 - val_loss: 0.4053\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3541\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3181 - val_loss: 0.3406\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3171 - val_loss: 0.3274\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.3429\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3124 - val_loss: 0.3282\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.3390\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3308\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.3183\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.3331\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3065 - val_loss: 0.3195\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3152\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3060 - val_loss: 0.3161\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3328\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2980 - val_loss: 0.3069\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2992 - val_loss: 0.3151\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2984 - val_loss: 0.3239\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3364\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2979 - val_loss: 0.3161\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2956 - val_loss: 0.3110\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 0.3232\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.3145\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3038\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2909 - val_loss: 0.3232\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2904 - val_loss: 0.3308\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2902 - val_loss: 0.3343\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2890 - val_loss: 0.3012\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2887 - val_loss: 0.3226\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.3226\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2871 - val_loss: 0.3139\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2860 - val_loss: 0.3108\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2872 - val_loss: 0.3517\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3571\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2841 - val_loss: 0.3209\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2809 - val_loss: 0.3081\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2800 - val_loss: 0.3305\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2803 - val_loss: 0.3666\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3076\n",
            "[CV]  n_neurons=23, n_hidden=3, learning_rate=0.0277582354248053, total=  24.6s\n",
            "[CV] n_neurons=10, n_hidden=2, learning_rate=0.0057727097827401045 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.9773 - val_loss: 0.7913\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.5801\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5573\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.6161\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.5330\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.5173\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.5048\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.5176\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.4903\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4890\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4848\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4216 - val_loss: 0.4840\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4882\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.4654\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.5072\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4712\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.4979\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4535\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4598\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4437\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.4567\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.4401\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4374\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.4353\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.6273\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.4271\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.4451\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4289\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4291\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 0.4180\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.4385\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.4136\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.4805\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.4080\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3575 - val_loss: 0.4065\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.4009\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.4549\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 0.4047\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3951\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.4007\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.4225\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.3946\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3879\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3893\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3863\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.3911\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3873\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.3833\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3359 - val_loss: 0.3871\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3878\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3771\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.4075\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.3865\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3750\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3773\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.3742\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3717\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3261 - val_loss: 0.3673\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.3675\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.3853\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3714\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3266 - val_loss: 0.3647\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3684\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.3620\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3195 - val_loss: 0.3693\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3202 - val_loss: 0.3624\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3181 - val_loss: 0.3781\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3213 - val_loss: 0.3599\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3225 - val_loss: 0.3734\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.3599\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3185 - val_loss: 0.3614\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3180 - val_loss: 0.3767\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3151 - val_loss: 0.5063\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3185 - val_loss: 0.3537\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3140 - val_loss: 0.3568\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3551\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3630\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3557\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.3683\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3628\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3526\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3134 - val_loss: 0.3611\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3115 - val_loss: 0.3523\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3107 - val_loss: 0.3506\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3091 - val_loss: 0.3554\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.3573\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3085 - val_loss: 0.3587\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3531\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3605\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.3476\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3086 - val_loss: 0.3551\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3818\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.3738\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3527\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3486\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3584\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3055 - val_loss: 0.3517\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3094 - val_loss: 0.3491\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3039 - val_loss: 0.3456\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.3487\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3553\n",
            "[CV]  n_neurons=10, n_hidden=2, learning_rate=0.0057727097827401045, total= 1.4min\n",
            "[CV] n_neurons=10, n_hidden=2, learning_rate=0.0057727097827401045 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1676 - val_loss: 0.7381\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.6220\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 0.5861\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.5224\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.5212\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.4997\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4741\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4911\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 0.4641\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 0.4644\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4525\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4559\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.4566\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.4489\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4379\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4399\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4398\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4294\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3898 - val_loss: 0.4274\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4366\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.4291\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.4321\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4189\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4208\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.4123\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4223\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4116\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.4067\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4460\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.4031\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3994\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.4026\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.3991\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.3944\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 0.3992\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3895\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 0.3898\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3879\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3906\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3835\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3530 - val_loss: 0.3839\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 0.3851\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3845\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 0.3840\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3477 - val_loss: 0.3748\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.3805\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3744\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3738\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3697\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3710\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3747\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.3714\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3715\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3690\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.3683\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3661\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3631\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.3624\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3592\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3603\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3328 - val_loss: 0.3597\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3581\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3587\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.3547\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3596\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.3530\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3547\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3267 - val_loss: 0.3597\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3258 - val_loss: 0.3545\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3573\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 0.3541\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3501\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3246 - val_loss: 0.3565\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3537\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3224 - val_loss: 0.3509\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3224 - val_loss: 0.3507\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3501\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.3566\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.3539\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3202 - val_loss: 0.3585\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3220 - val_loss: 0.3493\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3217 - val_loss: 0.3508\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3480\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3476\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.3462\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3435\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3444\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.3462\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3185 - val_loss: 0.3524\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3173 - val_loss: 0.3415\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3170 - val_loss: 0.3454\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3447\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3151 - val_loss: 0.3479\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.3483\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3159 - val_loss: 0.3436\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3429\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3460\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3158 - val_loss: 0.3446\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.3474\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3435\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3201\n",
            "[CV]  n_neurons=10, n_hidden=2, learning_rate=0.0057727097827401045, total=  43.1s\n",
            "[CV] n_neurons=10, n_hidden=2, learning_rate=0.0057727097827401045 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.6104 - val_loss: 0.7969\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6821 - val_loss: 0.6671\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6192\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - val_loss: 0.5854\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.5614\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5459\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.5273\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.5155\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5084\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5014\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5003\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4888\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.4851\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4812\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4767\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4759\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.4680\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4709\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4613\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4378 - val_loss: 0.4592\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.4546\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4719\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 0.4499\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 0.4625\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4449\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.4406\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.4410\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4404\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4477\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 0.4350\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.4279\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4289\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.4575\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.4287\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 0.4180\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4381\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4129\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4189\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.4183\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 0.4110\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.4152\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4102\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4076\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4002\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4048\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.3985\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.3998\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.3999\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4027\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4012\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3944\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3913\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3942\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.3891\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.3872\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.3846\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.3877\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.3861\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.3853\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3934\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.3837\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.3808\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 0.3838\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3563 - val_loss: 0.3821\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.3833\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3542 - val_loss: 0.3787\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.3776\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 0.3870\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.3772\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3842\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.3796\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3958\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.3760\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3493 - val_loss: 0.3730\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3757\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3825\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3798\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.3720\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.3742\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.3702\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3747\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.3715\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3706\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.3734\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.3696\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3803\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3872\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3669\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3784\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3734\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3757\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3753\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3633\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3742\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.3692\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3431 - val_loss: 0.3670\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 0.3650\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3418 - val_loss: 0.3604\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3670\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.3629\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3083\n",
            "[CV]  n_neurons=10, n_hidden=2, learning_rate=0.0057727097827401045, total= 1.4min\n",
            "[CV] n_neurons=53, n_hidden=0, learning_rate=0.000676117895925769 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 6.1256 - val_loss: 4.2367\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.2993 - val_loss: 2.4885\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.9247 - val_loss: 1.5859\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.2372 - val_loss: 1.1147\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8880 - val_loss: 0.8662\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7082 - val_loss: 0.7351\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6636\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 0.6242\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 0.6026\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5902\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.5825\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 0.5784\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 0.5753\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.5729\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.5715\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5039 - val_loss: 0.5704\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 0.5706\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5024 - val_loss: 0.5697\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 0.5690\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 0.5689\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5008 - val_loss: 0.5684\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5679\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4998 - val_loss: 0.5681\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5682\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4990 - val_loss: 0.5675\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4987 - val_loss: 0.5677\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.5667\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.5668\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.5667\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.5667\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.5667\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.5657\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.5657\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.5655\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4961 - val_loss: 0.5655\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5656\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5657\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5663\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.5666\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5668\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5663\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.5660\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5661\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4945 - val_loss: 0.5658\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5363\n",
            "[CV]  n_neurons=53, n_hidden=0, learning_rate=0.000676117895925769, total=  19.4s\n",
            "[CV] n_neurons=53, n_hidden=0, learning_rate=0.000676117895925769 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 5.0079 - val_loss: 3.6618\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.8704 - val_loss: 2.2506\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8006 - val_loss: 1.5177\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.2477 - val_loss: 1.1278\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9529 - val_loss: 0.9152\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7915 - val_loss: 0.7960\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 0.7296\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6502 - val_loss: 0.6894\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6647\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 0.6501\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5888 - val_loss: 0.6399\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5804 - val_loss: 0.6332\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 0.6287\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5695 - val_loss: 0.6247\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - val_loss: 0.6215\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5621 - val_loss: 0.6182\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5592 - val_loss: 0.6160\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - val_loss: 0.6133\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5538 - val_loss: 0.6110\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.6111\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.6081\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.6061\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.6038\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5432 - val_loss: 0.6030\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.6009\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.6000\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 0.5994\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5364 - val_loss: 0.5986\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 0.5973\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 0.5959\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.5959\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.5944\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.5931\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 0.5935\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.5921\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 0.5920\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5903\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5902\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.5889\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5889\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.5875\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 0.5885\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 0.5867\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5875\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 0.5875\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 0.5872\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5170 - val_loss: 0.5872\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 0.5869\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.5860\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.5856\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5843\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.5857\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.5832\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5131 - val_loss: 0.5832\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5823\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5123 - val_loss: 0.5837\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.5833\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.5834\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5110 - val_loss: 0.5836\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5105 - val_loss: 0.5826\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 0.5811\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5100 - val_loss: 0.5813\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.5828\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 0.5821\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 0.5823\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5830\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.5829\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.5824\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.5826\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5823\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5811\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5191\n",
            "[CV]  n_neurons=53, n_hidden=0, learning_rate=0.000676117895925769, total=  30.8s\n",
            "[CV] n_neurons=53, n_hidden=0, learning_rate=0.000676117895925769 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 5.4148 - val_loss: 4.2467\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.0318 - val_loss: 2.4416\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8812 - val_loss: 1.5860\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.3094 - val_loss: 1.1652\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0163 - val_loss: 0.9492\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8600 - val_loss: 0.8331\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7731 - val_loss: 0.7672\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.7272\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6895 - val_loss: 0.7011\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6678 - val_loss: 0.6829\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6520 - val_loss: 0.6692\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6397 - val_loss: 0.6584\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6297 - val_loss: 0.6496\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.6421\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6357\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6300\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6249\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 0.6204\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 0.6164\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5878 - val_loss: 0.6127\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5838 - val_loss: 0.6093\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5802 - val_loss: 0.6063\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5769 - val_loss: 0.6035\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.6009\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - val_loss: 0.5985\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5962\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - val_loss: 0.5942\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5634 - val_loss: 0.5924\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5611 - val_loss: 0.5906\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 0.5889\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5571 - val_loss: 0.5873\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.5860\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 0.5846\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.5832\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 0.5820\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5489 - val_loss: 0.5809\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5475 - val_loss: 0.5799\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.5788\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.5779\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.5771\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 0.5762\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5416 - val_loss: 0.5756\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 0.5749\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 0.5743\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 0.5739\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 0.5734\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.5727\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5362 - val_loss: 0.5722\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5355 - val_loss: 0.5717\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5348 - val_loss: 0.5712\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.5708\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 0.5702\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.5701\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 0.5696\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.5694\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.5691\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.5688\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.5684\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.5679\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.5677\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.5677\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 0.5677\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.5677\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 0.5675\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.5672\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.5671\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5672\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.5669\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.5666\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 0.5662\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5663\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.5664\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.5665\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5663\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5663\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.5661\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.5660\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5659\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 0.5657\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5661\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5664\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.5662\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.5662\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5659\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5658\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.5659\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5658\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 0.5654\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 0.5656\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5657\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5658\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 0.5654\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 0.5657\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5655\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5659\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5662\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5662\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5663\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4783\n",
            "[CV]  n_neurons=53, n_hidden=0, learning_rate=0.000676117895925769, total=  43.6s\n",
            "[CV] n_neurons=9, n_hidden=0, learning_rate=0.004502515493215178 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.5806 - val_loss: 0.7551\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6340\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5634 - val_loss: 0.6115\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5432 - val_loss: 0.5944\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.5837\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5849\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5760\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 0.6007\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5983\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.5675\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.5723\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.5804\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4996 - val_loss: 0.6323\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 0.5786\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.6106\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5619\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5623\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5616\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5710\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.5636\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.6347\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4992 - val_loss: 0.6068\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.6219\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.5651\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.6108\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.6127\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4987 - val_loss: 0.6008\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5634\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5349\n",
            "[CV]  n_neurons=9, n_hidden=0, learning_rate=0.004502515493215178, total=  12.9s\n",
            "[CV] n_neurons=9, n_hidden=0, learning_rate=0.004502515493215178 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2702 - val_loss: 0.9182\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1920 - val_loss: 1.0650\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.5528\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.6330 - val_loss: 2.4107\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 6.4516 - val_loss: 4.2588\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 12.4459 - val_loss: 7.6373\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 24.0140 - val_loss: 14.5191\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 47.0925 - val_loss: 27.3133\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 71.6589 - val_loss: 53.8066\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 136.4865 - val_loss: 102.8138\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 326.3119 - val_loss: 201.8573\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 288.8869\n",
            "[CV]  n_neurons=9, n_hidden=0, learning_rate=0.004502515493215178, total=   5.3s\n",
            "[CV] n_neurons=9, n_hidden=0, learning_rate=0.004502515493215178 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2102 - val_loss: 0.8055\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6866 - val_loss: 0.6821\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6302 - val_loss: 0.6474\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6252\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 0.6092\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 0.5984\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5577 - val_loss: 0.5940\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5498 - val_loss: 0.5861\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 0.5780\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 0.5853\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 0.5713\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.5841\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.5683\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 0.5653\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.5703\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5756\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.5707\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.5729\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5683\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5644\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.5823\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5681\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5687\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5709\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5700\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5669\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 0.5688\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 0.5630\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5669\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 0.5631\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5744\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 0.5803\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.5668\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 0.5747\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5721\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5639\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5610\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.5731\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5640\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.5766\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5719\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.5650\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5683\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5676\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5771\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5720\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.5711\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4747\n",
            "[CV]  n_neurons=9, n_hidden=0, learning_rate=0.004502515493215178, total=  21.2s\n",
            "[CV] n_neurons=53, n_hidden=2, learning_rate=0.0005178813624007193 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.0646 - val_loss: 1.7195\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.3604 - val_loss: 1.1319\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8959 - val_loss: 0.9033\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7684 - val_loss: 0.8201\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7121 - val_loss: 0.7745\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6792 - val_loss: 0.7451\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6560 - val_loss: 0.7235\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6379 - val_loss: 0.7051\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.6905\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6768\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5976 - val_loss: 0.6643\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5870 - val_loss: 0.6547\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5774 - val_loss: 0.6447\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5685 - val_loss: 0.6351\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.6272\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5527 - val_loss: 0.6191\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.6119\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5391 - val_loss: 0.6049\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.5983\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5271 - val_loss: 0.5935\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.5868\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5166 - val_loss: 0.5813\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5118 - val_loss: 0.5769\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5072 - val_loss: 0.5716\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5675\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.5632\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.5586\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.5547\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.5508\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.5471\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4805 - val_loss: 0.5437\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.5397\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4741 - val_loss: 0.5370\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.5337\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5307\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.5276\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.5245\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.5225\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.5197\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5172\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.5143\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.5118\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.5102\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.5077\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4454 - val_loss: 0.5057\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4436 - val_loss: 0.5030\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.5009\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4993\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4383 - val_loss: 0.4984\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4366 - val_loss: 0.4976\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4947\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 0.4921\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4914\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.4895\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.4879\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.4860\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4850\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4832\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4245 - val_loss: 0.4818\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.4813\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.4799\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.4779\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 0.4777\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4191 - val_loss: 0.4759\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.4742\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4733\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.4721\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.4716\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.4707\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 0.4696\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4126 - val_loss: 0.4688\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4117 - val_loss: 0.4677\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.4666\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4102 - val_loss: 0.4655\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4651\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4641\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4080 - val_loss: 0.4629\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.4627\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4066 - val_loss: 0.4616\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4608\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.4608\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.4607\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4039 - val_loss: 0.4594\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4583\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.4571\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4572\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4561\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.4555\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.4549\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3998 - val_loss: 0.4540\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4534\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3986 - val_loss: 0.4528\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4520\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4516\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4513\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3964 - val_loss: 0.4507\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4501\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4498\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.4493\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4490\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4434\n",
            "[CV]  n_neurons=53, n_hidden=2, learning_rate=0.0005178813624007193, total=  49.6s\n",
            "[CV] n_neurons=53, n_hidden=2, learning_rate=0.0005178813624007193 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.7479 - val_loss: 1.5578\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1328 - val_loss: 0.9960\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8434 - val_loss: 0.8444\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7569 - val_loss: 0.7873\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7146 - val_loss: 0.7517\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6869 - val_loss: 0.7275\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6645 - val_loss: 0.7113\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6456 - val_loss: 0.6931\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6289 - val_loss: 0.6785\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6634\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6499\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5887 - val_loss: 0.6398\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5772 - val_loss: 0.6330\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5670 - val_loss: 0.6195\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5577 - val_loss: 0.6135\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5488 - val_loss: 0.6026\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5405 - val_loss: 0.5938\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5330 - val_loss: 0.5862\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5259 - val_loss: 0.5798\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5759\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5129 - val_loss: 0.5707\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 0.5633\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5017 - val_loss: 0.5576\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4967 - val_loss: 0.5563\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4917 - val_loss: 0.5491\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5443\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4834 - val_loss: 0.5399\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5391\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4761 - val_loss: 0.5375\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5311\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.5299\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5284\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4634 - val_loss: 0.5211\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.5190\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.5170\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4565 - val_loss: 0.5150\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.5124\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4522 - val_loss: 0.5107\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4504 - val_loss: 0.5086\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.5072\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4465 - val_loss: 0.5044\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4449 - val_loss: 0.5030\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.5038\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.5010\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4401 - val_loss: 0.4984\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4387 - val_loss: 0.4968\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4985\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4942\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 0.4932\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.4909\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.4903\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.4871\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 0.4872\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4856\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4278 - val_loss: 0.4834\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4819\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4812\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4245 - val_loss: 0.4807\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4233 - val_loss: 0.4777\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 0.4773\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.4792\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4753\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4199 - val_loss: 0.4749\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4752\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.4728\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.4714\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.4711\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.4707\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.4698\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.4702\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4673\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.4698\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4119 - val_loss: 0.4650\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.4659\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.4639\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4603\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.4642\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 0.4602\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.4585\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.4586\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4062 - val_loss: 0.4582\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.4581\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 0.4570\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.4560\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4037 - val_loss: 0.4564\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.4552\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4543\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4526\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4523\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4511\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4502\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3996 - val_loss: 0.4492\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3988 - val_loss: 0.4509\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4484\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.4482\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.4464\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4460\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4470\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.4445\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.4448\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4112\n",
            "[CV]  n_neurons=53, n_hidden=2, learning_rate=0.0005178813624007193, total=  50.9s\n",
            "[CV] n_neurons=53, n_hidden=2, learning_rate=0.0005178813624007193 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.0142 - val_loss: 1.5393\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1632 - val_loss: 1.0389\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9120 - val_loss: 0.8894\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8138 - val_loss: 0.8115\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7569 - val_loss: 0.7650\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7195 - val_loss: 0.7337\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6917 - val_loss: 0.7105\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6701 - val_loss: 0.6914\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6516 - val_loss: 0.6752\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.6605\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6219 - val_loss: 0.6478\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6094 - val_loss: 0.6359\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5982 - val_loss: 0.6253\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5879 - val_loss: 0.6157\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5784 - val_loss: 0.6071\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5699 - val_loss: 0.5988\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5619 - val_loss: 0.5913\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5546 - val_loss: 0.5843\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5478 - val_loss: 0.5779\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5414 - val_loss: 0.5722\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.5667\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.5614\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5251 - val_loss: 0.5566\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5204 - val_loss: 0.5522\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5161 - val_loss: 0.5478\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.5439\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5082 - val_loss: 0.5402\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5046 - val_loss: 0.5368\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 0.5335\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.5303\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4949 - val_loss: 0.5274\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5244\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.5217\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4868 - val_loss: 0.5192\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4843 - val_loss: 0.5166\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5144\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4796 - val_loss: 0.5121\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4775 - val_loss: 0.5099\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4754 - val_loss: 0.5080\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5058\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4715 - val_loss: 0.5038\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4697 - val_loss: 0.5020\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4678 - val_loss: 0.5006\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.4981\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4646 - val_loss: 0.4968\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4630 - val_loss: 0.4951\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4938\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4601 - val_loss: 0.4921\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4585 - val_loss: 0.4903\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.4889\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.4875\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4546 - val_loss: 0.4860\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.4846\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4522 - val_loss: 0.4833\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4825\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4497 - val_loss: 0.4808\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.4797\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.4786\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4464 - val_loss: 0.4775\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.4764\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4443 - val_loss: 0.4752\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4433 - val_loss: 0.4740\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4731\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4720\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.4710\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.4699\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 0.4690\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4680\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4671\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4664\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.4653\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4647\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4636\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.4627\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4317 - val_loss: 0.4621\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4612\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4302 - val_loss: 0.4609\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 0.4599\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4289 - val_loss: 0.4592\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4282 - val_loss: 0.4585\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4577\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4571\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4262 - val_loss: 0.4564\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.4561\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.4552\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.4547\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.4540\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4232 - val_loss: 0.4535\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.4532\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 0.4524\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 0.4518\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.4516\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4509\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.4505\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4196 - val_loss: 0.4500\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4191 - val_loss: 0.4492\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4186 - val_loss: 0.4487\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4482\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4176 - val_loss: 0.4476\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4172 - val_loss: 0.4473\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3852\n",
            "[CV]  n_neurons=53, n_hidden=2, learning_rate=0.0005178813624007193, total= 1.4min\n",
            "[CV] n_neurons=41, n_hidden=0, learning_rate=0.0011984120299382724 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.5408 - val_loss: 2.6537\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7889 - val_loss: 1.3925\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0575 - val_loss: 0.9949\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8222 - val_loss: 0.8486\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7338 - val_loss: 0.7852\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6925 - val_loss: 0.7510\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6683 - val_loss: 0.7268\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6507 - val_loss: 0.7088\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.6941\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.6809\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6694\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6592\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5923 - val_loss: 0.6498\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5837 - val_loss: 0.6414\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5760 - val_loss: 0.6341\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 0.6274\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 0.6212\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5563 - val_loss: 0.6155\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5507 - val_loss: 0.6101\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.6066\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.6018\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 0.5985\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 0.5963\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 0.5944\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5926\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5875\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.5842\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5836\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.5832\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 0.5801\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.5791\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.5760\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 0.5758\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5737\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5072 - val_loss: 0.5745\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 0.5741\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.5742\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.5716\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5707\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.5695\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5716\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.5699\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4999 - val_loss: 0.5687\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5681\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4987 - val_loss: 0.5721\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4982 - val_loss: 0.5685\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.5694\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.5705\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.5719\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.5677\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4963 - val_loss: 0.5665\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5658\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5664\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5688\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4953 - val_loss: 0.5713\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.5701\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.5711\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.5692\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4946 - val_loss: 0.5683\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5713\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5702\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.5705\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5340\n",
            "[CV]  n_neurons=41, n_hidden=0, learning_rate=0.0011984120299382724, total=  41.6s\n",
            "[CV] n_neurons=41, n_hidden=0, learning_rate=0.0011984120299382724 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.9473 - val_loss: 2.6132\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7550 - val_loss: 1.2812\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9692 - val_loss: 0.8700\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7274 - val_loss: 0.7316\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 0.6799\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6084 - val_loss: 0.6547\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5929 - val_loss: 0.6445\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.6368\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.6326\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5697 - val_loss: 0.6253\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5643 - val_loss: 0.6203\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5598 - val_loss: 0.6185\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5550 - val_loss: 0.6122\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5513 - val_loss: 0.6092\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5477 - val_loss: 0.6094\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5443 - val_loss: 0.6061\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5411 - val_loss: 0.6063\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5387 - val_loss: 0.6033\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5999\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 0.5971\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.5958\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.5930\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 0.5958\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.5910\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5909\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5898\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5204 - val_loss: 0.5913\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5191 - val_loss: 0.5871\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 0.5907\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5170 - val_loss: 0.5888\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5160 - val_loss: 0.5871\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5897\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.5872\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.5872\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 0.5836\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5808\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5835\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5107 - val_loss: 0.5827\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 0.5839\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.5849\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 0.5834\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5085 - val_loss: 0.5885\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5841\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5809\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5818\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5072 - val_loss: 0.5833\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5189\n",
            "[CV]  n_neurons=41, n_hidden=0, learning_rate=0.0011984120299382724, total=  22.7s\n",
            "[CV] n_neurons=41, n_hidden=0, learning_rate=0.0011984120299382724 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.8109 - val_loss: 2.6782\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.6916 - val_loss: 1.2056\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8931 - val_loss: 0.7861\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6608 - val_loss: 0.6562\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5886 - val_loss: 0.6135\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5647 - val_loss: 0.5991\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.5924\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 0.5887\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5488 - val_loss: 0.5868\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5467 - val_loss: 0.5853\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5449 - val_loss: 0.5840\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 0.5835\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5418 - val_loss: 0.5828\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.5807\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5391 - val_loss: 0.5786\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 0.5779\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.5772\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 0.5771\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 0.5763\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.5755\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.5755\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5325 - val_loss: 0.5760\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5752\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 0.5748\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 0.5734\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5738\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5292 - val_loss: 0.5738\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.5736\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5739\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 0.5733\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5275 - val_loss: 0.5734\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 0.5727\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.5713\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.5701\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.5716\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 0.5700\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5255 - val_loss: 0.5703\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5713\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5250 - val_loss: 0.5709\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.5707\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5695\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.5692\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5241 - val_loss: 0.5696\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.5691\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5237 - val_loss: 0.5686\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.5686\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5682\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 0.5681\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5695\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5698\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 0.5696\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5684\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5685\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5225 - val_loss: 0.5698\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.5690\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 0.5698\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5223 - val_loss: 0.5703\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.5692\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4790\n",
            "[CV]  n_neurons=41, n_hidden=0, learning_rate=0.0011984120299382724, total=  28.8s\n",
            "[CV] n_neurons=14, n_hidden=1, learning_rate=0.00037557277530728876 ..\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 6.0429 - val_loss: 4.2130\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.0560 - val_loss: 2.4075\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8742 - val_loss: 1.6014\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3168 - val_loss: 1.2075\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0392 - val_loss: 1.0095\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8873 - val_loss: 0.8999\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8025 - val_loss: 0.8351\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7530 - val_loss: 0.7959\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7226 - val_loss: 0.7710\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7019 - val_loss: 0.7538\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6869 - val_loss: 0.7411\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6754 - val_loss: 0.7312\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6660 - val_loss: 0.7234\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6582 - val_loss: 0.7165\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6514 - val_loss: 0.7106\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6453 - val_loss: 0.7053\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6398 - val_loss: 0.7003\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6347 - val_loss: 0.6958\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.6915\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.6874\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6212 - val_loss: 0.6835\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6172 - val_loss: 0.6799\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 0.6762\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6096 - val_loss: 0.6728\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6060 - val_loss: 0.6693\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6026 - val_loss: 0.6658\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5992 - val_loss: 0.6628\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5960 - val_loss: 0.6597\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5929 - val_loss: 0.6568\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5898 - val_loss: 0.6538\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5869 - val_loss: 0.6509\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5840 - val_loss: 0.6482\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5811 - val_loss: 0.6455\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 0.6428\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5757 - val_loss: 0.6400\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5731 - val_loss: 0.6376\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5705 - val_loss: 0.6353\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5680 - val_loss: 0.6329\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5656 - val_loss: 0.6302\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 0.6279\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 0.6256\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5586 - val_loss: 0.6233\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5563 - val_loss: 0.6210\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.6189\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5519 - val_loss: 0.6167\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5498 - val_loss: 0.6147\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5477 - val_loss: 0.6126\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.6103\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5436 - val_loss: 0.6083\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5416 - val_loss: 0.6064\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.6046\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5377 - val_loss: 0.6028\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 0.6008\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.5989\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.5973\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5304 - val_loss: 0.5954\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 0.5938\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5919\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5903\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5236 - val_loss: 0.5888\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5219 - val_loss: 0.5871\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.5856\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5188 - val_loss: 0.5843\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5173 - val_loss: 0.5826\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 0.5811\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5143 - val_loss: 0.5796\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.5782\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5115 - val_loss: 0.5768\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 0.5754\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5087 - val_loss: 0.5740\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5074 - val_loss: 0.5726\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 0.5714\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5048 - val_loss: 0.5702\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5035 - val_loss: 0.5688\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5023 - val_loss: 0.5677\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 0.5665\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4998 - val_loss: 0.5651\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4987 - val_loss: 0.5640\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4975 - val_loss: 0.5628\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4964 - val_loss: 0.5617\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4953 - val_loss: 0.5606\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4942 - val_loss: 0.5594\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5582\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4921 - val_loss: 0.5571\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5561\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4900 - val_loss: 0.5550\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5540\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.5529\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4870 - val_loss: 0.5520\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4861 - val_loss: 0.5510\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4852 - val_loss: 0.5501\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4842 - val_loss: 0.5491\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4833 - val_loss: 0.5480\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5472\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4815 - val_loss: 0.5464\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4806 - val_loss: 0.5453\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 0.5445\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4788 - val_loss: 0.5436\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4780 - val_loss: 0.5428\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4772 - val_loss: 0.5418\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5179\n",
            "[CV]  n_neurons=14, n_hidden=1, learning_rate=0.00037557277530728876, total= 1.4min\n",
            "[CV] n_neurons=14, n_hidden=1, learning_rate=0.00037557277530728876 ..\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.9850 - val_loss: 2.3951\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.9177 - val_loss: 1.6669\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.3969 - val_loss: 1.3165\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1516 - val_loss: 1.1525\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0277 - val_loss: 1.0633\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9561 - val_loss: 1.0080\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 0.9691\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8760 - val_loss: 0.9388\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8489 - val_loss: 0.9143\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8265 - val_loss: 0.8923\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8069 - val_loss: 0.8726\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7896 - val_loss: 0.8561\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7740 - val_loss: 0.8404\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7596 - val_loss: 0.8250\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7464 - val_loss: 0.8112\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7343 - val_loss: 0.7992\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7226 - val_loss: 0.7876\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7117 - val_loss: 0.7760\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7014 - val_loss: 0.7655\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6917 - val_loss: 0.7561\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6825 - val_loss: 0.7452\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6738 - val_loss: 0.7362\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6653 - val_loss: 0.7282\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6572 - val_loss: 0.7189\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6492 - val_loss: 0.7099\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6418 - val_loss: 0.7031\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6344 - val_loss: 0.6956\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.6893\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6205 - val_loss: 0.6811\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6138 - val_loss: 0.6745\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6678\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6620\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5956 - val_loss: 0.6569\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5900 - val_loss: 0.6510\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5848 - val_loss: 0.6453\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5797 - val_loss: 0.6399\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5749 - val_loss: 0.6353\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5703 - val_loss: 0.6323\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5658 - val_loss: 0.6256\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.6215\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5577 - val_loss: 0.6196\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5540 - val_loss: 0.6149\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5504 - val_loss: 0.6111\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 0.6095\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5437 - val_loss: 0.6067\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.6029\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 0.5977\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5349 - val_loss: 0.5982\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.5953\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.5929\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5914\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.5877\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5223 - val_loss: 0.5868\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 0.5832\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5816\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 0.5803\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5790\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 0.5771\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5097 - val_loss: 0.5767\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5078 - val_loss: 0.5735\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5060 - val_loss: 0.5724\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.5694\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5026 - val_loss: 0.5676\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5009 - val_loss: 0.5661\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4993 - val_loss: 0.5643\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.5610\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4959 - val_loss: 0.5643\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4944 - val_loss: 0.5616\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4925 - val_loss: 0.5572\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.5567\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5537\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5506\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5487\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.5459\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.5448\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5431\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4804 - val_loss: 0.5402\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4791 - val_loss: 0.5386\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5370\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5342\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4754 - val_loss: 0.5330\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.5309\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4733 - val_loss: 0.5313\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5307\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4712 - val_loss: 0.5288\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5277\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4694 - val_loss: 0.5263\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.5252\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.5244\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5229\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4659 - val_loss: 0.5222\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5211\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.5208\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.5206\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4626 - val_loss: 0.5188\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4619 - val_loss: 0.5174\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.5167\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.5158\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4597 - val_loss: 0.5166\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.5146\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4661\n",
            "[CV]  n_neurons=14, n_hidden=1, learning_rate=0.00037557277530728876, total= 1.4min\n",
            "[CV] n_neurons=14, n_hidden=1, learning_rate=0.00037557277530728876 ..\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.3671 - val_loss: 1.7091\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3354 - val_loss: 1.1911\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0073 - val_loss: 0.9889\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8760 - val_loss: 0.8866\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8117 - val_loss: 0.8316\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7745 - val_loss: 0.7994\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7495 - val_loss: 0.7752\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7303 - val_loss: 0.7578\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7142 - val_loss: 0.7420\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7000 - val_loss: 0.7295\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6872 - val_loss: 0.7168\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6754 - val_loss: 0.7052\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6645 - val_loss: 0.6947\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6542 - val_loss: 0.6859\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6448 - val_loss: 0.6770\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 0.6683\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.6607\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.6537\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6126 - val_loss: 0.6468\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6057 - val_loss: 0.6402\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 0.6334\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5933 - val_loss: 0.6273\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5877 - val_loss: 0.6223\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5823 - val_loss: 0.6174\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5773 - val_loss: 0.6128\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.6079\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5679 - val_loss: 0.6036\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5637 - val_loss: 0.5999\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5597 - val_loss: 0.5960\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5559 - val_loss: 0.5921\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.5891\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5488 - val_loss: 0.5857\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.5828\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 0.5799\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.5767\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.5743\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.5718\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5694\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5293 - val_loss: 0.5676\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 0.5653\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5249 - val_loss: 0.5626\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5605\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5586\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.5571\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5172 - val_loss: 0.5552\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.5538\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5138 - val_loss: 0.5524\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.5506\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5108 - val_loss: 0.5490\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 0.5479\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5080 - val_loss: 0.5458\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5066 - val_loss: 0.5448\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5054 - val_loss: 0.5430\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5042 - val_loss: 0.5417\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5030 - val_loss: 0.5401\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5019 - val_loss: 0.5392\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5008 - val_loss: 0.5385\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4998 - val_loss: 0.5377\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4988 - val_loss: 0.5367\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4978 - val_loss: 0.5355\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4969 - val_loss: 0.5342\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4960 - val_loss: 0.5333\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5319\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4942 - val_loss: 0.5309\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4934 - val_loss: 0.5298\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5293\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5293\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4910 - val_loss: 0.5276\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4903 - val_loss: 0.5266\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.5256\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5250\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5246\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4875 - val_loss: 0.5235\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5235\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4861 - val_loss: 0.5228\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4855 - val_loss: 0.5220\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4849 - val_loss: 0.5208\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4842 - val_loss: 0.5204\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.5196\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.5189\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4825 - val_loss: 0.5180\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4819 - val_loss: 0.5174\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.5172\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5167\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4803 - val_loss: 0.5157\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5151\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5144\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5137\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5133\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5126\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5121\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4769 - val_loss: 0.5113\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5108\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5101\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.5094\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4751 - val_loss: 0.5087\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4746 - val_loss: 0.5082\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4742 - val_loss: 0.5074\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.5071\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4733 - val_loss: 0.5070\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4382\n",
            "[CV]  n_neurons=14, n_hidden=1, learning_rate=0.00037557277530728876, total= 1.4min\n",
            "[CV] n_neurons=7, n_hidden=1, learning_rate=0.029561677041492953 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9939 - val_loss: 0.5873\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4833 - val_loss: 0.4960\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4857\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4218 - val_loss: 0.4680\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4169 - val_loss: 0.4804\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4583\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.4477\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.4599\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.4405\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4320\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4342\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.4214\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4568\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4224\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4176\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4205\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.4088\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.5119\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4003 - val_loss: 0.4381\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.4251\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4006\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4028\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.4038\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4072\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.4008\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.7804\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.4308\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4266\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.4335\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4254\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4740\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4478\n",
            "[CV]  n_neurons=7, n_hidden=1, learning_rate=0.029561677041492953, total=  17.5s\n",
            "[CV] n_neurons=7, n_hidden=1, learning_rate=0.029561677041492953 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8552 - val_loss: 0.5451\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4769 - val_loss: 0.4945\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4530 - val_loss: 0.4905\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4383 - val_loss: 0.8398\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 0.4686\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.4448\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.4383\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4352\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.6280\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.4284\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4266\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4157 - val_loss: 1.5646\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5661 - val_loss: 0.4603\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4252 - val_loss: 0.4486\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4385\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4580 - val_loss: 0.4513\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4395\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4300\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3942 - val_loss: 0.4345\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4178\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.4138\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4226\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.4126\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3752 - val_loss: 0.4073\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4123\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3689 - val_loss: 0.4155\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.4068\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.4096\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.4118\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4007\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.4067\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.4074\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.4114\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.4025\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.4022\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.4217\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.4007\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.4117\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3604 - val_loss: 0.3965\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3950\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.3998\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3590 - val_loss: 0.4060\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3587 - val_loss: 0.4015\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.3927\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3565 - val_loss: 0.3949\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.3923\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3602 - val_loss: 0.3957\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.4815\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.4090\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3615 - val_loss: 0.4019\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.4082\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3975\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3619 - val_loss: 0.3923\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3953\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3638 - val_loss: 0.3989\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3599 - val_loss: 0.3818\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3548 - val_loss: 0.3922\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3894\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 0.3950\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.3906\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.3822\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3903\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3785\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.4101\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4251\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.3979\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3874\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3554 - val_loss: 0.3946\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3803\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3935\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3802\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3835\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3824\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3624\n",
            "[CV]  n_neurons=7, n_hidden=1, learning_rate=0.029561677041492953, total=  39.2s\n",
            "[CV] n_neurons=7, n_hidden=1, learning_rate=0.029561677041492953 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7703 - val_loss: 0.6029\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5198 - val_loss: 0.5459\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4832 - val_loss: 0.4882\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.4857\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 0.4590\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4421 - val_loss: 0.4444\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4400 - val_loss: 0.4401\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4317 - val_loss: 0.4401\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.4308\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.4413\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.4486\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4197\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4265\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.4250\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.4314\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4118\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.5773\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.4229\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4041\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.4106\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4042\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3870 - val_loss: 0.4032\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.3948\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.4054\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3862\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.3879\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.3841\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.3839\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3783 - val_loss: 0.3912\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.3897\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.3859\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4089\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3762\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.3825\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.3845\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.3764\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.3833\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3812\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.3803\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3762\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3781\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.4007\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3785\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3216\n",
            "[CV]  n_neurons=7, n_hidden=1, learning_rate=0.029561677041492953, total=  23.6s\n",
            "[CV] n_neurons=26, n_hidden=0, learning_rate=0.014831860605002889 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.6458 - val_loss: 3.6326\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 133.0241 - val_loss: 66.3437\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1785.0543 - val_loss: 1561.5648\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 28231.2637 - val_loss: 33714.1406\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 59888.7617 - val_loss: 733297.1250\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1498937.5000 - val_loss: 16793560.0000\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 35029012.0000 - val_loss: 355026240.0000\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3035851008.0000 - val_loss: 7778628096.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 16298531840.0000 - val_loss: 162418999296.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 369592336384.0000 - val_loss: 3646058397696.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 174239122456576.0000 - val_loss: 81540558094336.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 2582319726592.0000\n",
            "[CV]  n_neurons=26, n_hidden=0, learning_rate=0.014831860605002889, total=  10.9s\n",
            "[CV] n_neurons=26, n_hidden=0, learning_rate=0.014831860605002889 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8804 - val_loss: 2.8341\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 5.6185 - val_loss: 55.4385\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 88.9681 - val_loss: 1383.9661\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2385.2781 - val_loss: 34505.9336\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 57322.9961 - val_loss: 869282.3125\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1854435.5000 - val_loss: 21257882.0000\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 39726532.0000 - val_loss: 531497888.0000\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 827457856.0000 - val_loss: 13381499904.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 20931913728.0000 - val_loss: 333065879552.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2909977968640.0000 - val_loss: 8337571184640.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 74074168492032.0000 - val_loss: 209329777016832.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 303883800805376.0000\n",
            "[CV]  n_neurons=26, n_hidden=0, learning_rate=0.014831860605002889, total=  10.9s\n",
            "[CV] n_neurons=26, n_hidden=0, learning_rate=0.014831860605002889 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1085 - val_loss: 0.6232\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5642 - val_loss: 0.5753\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5400 - val_loss: 0.5679\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5320 - val_loss: 0.5640\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.5597\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.5758\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5252 - val_loss: 0.5666\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5328 - val_loss: 0.5747\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.5813\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5375 - val_loss: 0.5987\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.5725\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5398 - val_loss: 0.5734\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5640\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5801\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 0.5903\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4780\n",
            "[CV]  n_neurons=26, n_hidden=0, learning_rate=0.014831860605002889, total=   8.4s\n",
            "[CV] n_neurons=29, n_hidden=0, learning_rate=0.0004225431080276861 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 7.4327 - val_loss: 6.0622\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.9149 - val_loss: 4.1250\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.3748 - val_loss: 2.9273\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.4135 - val_loss: 2.1702\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8022 - val_loss: 1.6826\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4092 - val_loss: 1.3653\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1537 - val_loss: 1.1550\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9858 - val_loss: 1.0146\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8744 - val_loss: 0.9195\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7997 - val_loss: 0.8545\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7490 - val_loss: 0.8088\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7141 - val_loss: 0.7771\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6896 - val_loss: 0.7539\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6719 - val_loss: 0.7367\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6589 - val_loss: 0.7238\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6489 - val_loss: 0.7144\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6411 - val_loss: 0.7056\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6347 - val_loss: 0.6984\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6292 - val_loss: 0.6929\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6244 - val_loss: 0.6881\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.6835\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6162 - val_loss: 0.6788\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6127 - val_loss: 0.6751\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6712\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6059 - val_loss: 0.6682\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6652\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5996 - val_loss: 0.6619\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5968 - val_loss: 0.6589\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5941 - val_loss: 0.6565\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5913 - val_loss: 0.6539\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5887 - val_loss: 0.6519\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5861 - val_loss: 0.6493\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5837 - val_loss: 0.6470\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5812 - val_loss: 0.6445\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5788 - val_loss: 0.6420\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5766 - val_loss: 0.6397\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5745 - val_loss: 0.6383\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5722 - val_loss: 0.6369\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - val_loss: 0.6352\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5681 - val_loss: 0.6329\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5662 - val_loss: 0.6312\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5642 - val_loss: 0.6290\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5623 - val_loss: 0.6270\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5606 - val_loss: 0.6257\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5588 - val_loss: 0.6245\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5570 - val_loss: 0.6228\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5554 - val_loss: 0.6210\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5538 - val_loss: 0.6198\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5522 - val_loss: 0.6190\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5506 - val_loss: 0.6171\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.6155\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.6144\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.6132\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.6119\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5436 - val_loss: 0.6107\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5423 - val_loss: 0.6096\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.6093\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5398 - val_loss: 0.6083\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 0.6071\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.6065\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5362 - val_loss: 0.6048\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.6043\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5341 - val_loss: 0.6033\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5331 - val_loss: 0.6029\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.6023\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.6014\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 0.6004\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5291 - val_loss: 0.5996\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.5981\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5273 - val_loss: 0.5971\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5264 - val_loss: 0.5962\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5256 - val_loss: 0.5959\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5248 - val_loss: 0.5953\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.5944\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5232 - val_loss: 0.5944\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5221 - val_loss: 0.5936\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5217 - val_loss: 0.5930\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.5922\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 0.5913\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.5905\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.5898\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 0.5896\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5176 - val_loss: 0.5896\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5170 - val_loss: 0.5896\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5164 - val_loss: 0.5894\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.5888\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 0.5886\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5147 - val_loss: 0.5875\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.5866\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5136 - val_loss: 0.5863\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5130 - val_loss: 0.5854\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5126 - val_loss: 0.5855\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.5851\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 0.5849\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5840\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5107 - val_loss: 0.5833\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.5831\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5098 - val_loss: 0.5825\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5819\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5091 - val_loss: 0.5823\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5488\n",
            "[CV]  n_neurons=29, n_hidden=0, learning_rate=0.0004225431080276861, total=  53.0s\n",
            "[CV] n_neurons=29, n_hidden=0, learning_rate=0.0004225431080276861 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 7.2010 - val_loss: 5.6943\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.8633 - val_loss: 3.9763\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.4016 - val_loss: 2.8876\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.4740 - val_loss: 2.1873\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8782 - val_loss: 1.7308\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4919 - val_loss: 1.4311\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.2395 - val_loss: 1.2320\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0725 - val_loss: 1.0977\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9611 - val_loss: 1.0061\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8857 - val_loss: 0.9425\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8338 - val_loss: 0.8973\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7973 - val_loss: 0.8643\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7709 - val_loss: 0.8393\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7512 - val_loss: 0.8201\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7360 - val_loss: 0.8043\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7238 - val_loss: 0.7915\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7136 - val_loss: 0.7805\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7048 - val_loss: 0.7706\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6970 - val_loss: 0.7620\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6899 - val_loss: 0.7540\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6834 - val_loss: 0.7464\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6773 - val_loss: 0.7392\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6715 - val_loss: 0.7325\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6659 - val_loss: 0.7262\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6607 - val_loss: 0.7199\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6556 - val_loss: 0.7140\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6507 - val_loss: 0.7084\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6460 - val_loss: 0.7031\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6414 - val_loss: 0.6979\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6371 - val_loss: 0.6930\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6328 - val_loss: 0.6880\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.6834\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6246 - val_loss: 0.6791\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6208 - val_loss: 0.6748\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6706\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6134 - val_loss: 0.6667\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6099 - val_loss: 0.6629\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6065 - val_loss: 0.6592\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6032 - val_loss: 0.6556\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6522\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 0.6489\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5940 - val_loss: 0.6457\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5911 - val_loss: 0.6427\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5883 - val_loss: 0.6397\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5856 - val_loss: 0.6369\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5829 - val_loss: 0.6342\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5804 - val_loss: 0.6315\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5779 - val_loss: 0.6290\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5755 - val_loss: 0.6266\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5732 - val_loss: 0.6242\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5710 - val_loss: 0.6219\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 0.6198\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5667 - val_loss: 0.6177\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 0.6157\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5627 - val_loss: 0.6138\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - val_loss: 0.6119\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5589 - val_loss: 0.6102\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5571 - val_loss: 0.6084\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5554 - val_loss: 0.6067\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5537 - val_loss: 0.6050\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5521 - val_loss: 0.6036\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5505 - val_loss: 0.6022\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.6007\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5475 - val_loss: 0.5994\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - val_loss: 0.5980\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 0.5968\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - val_loss: 0.5956\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5421 - val_loss: 0.5944\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.5932\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 0.5922\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5384 - val_loss: 0.5913\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.5905\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5361 - val_loss: 0.5893\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5350 - val_loss: 0.5886\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.5878\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5330 - val_loss: 0.5869\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5320 - val_loss: 0.5862\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - val_loss: 0.5854\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5301 - val_loss: 0.5844\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5293 - val_loss: 0.5837\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5284 - val_loss: 0.5832\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.5825\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 0.5818\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 0.5810\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5252 - val_loss: 0.5806\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5245 - val_loss: 0.5799\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.5793\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5791\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 0.5787\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5218 - val_loss: 0.5784\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5211 - val_loss: 0.5780\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5205 - val_loss: 0.5773\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5200 - val_loss: 0.5770\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 0.5768\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.5762\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5183 - val_loss: 0.5759\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5757\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5173 - val_loss: 0.5753\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5752\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5163 - val_loss: 0.5751\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5269\n",
            "[CV]  n_neurons=29, n_hidden=0, learning_rate=0.0004225431080276861, total=  53.0s\n",
            "[CV] n_neurons=29, n_hidden=0, learning_rate=0.0004225431080276861 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 5.9277 - val_loss: 5.0481\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.1945 - val_loss: 3.6572\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.0809 - val_loss: 2.7564\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.3569 - val_loss: 2.1668\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8803 - val_loss: 1.7748\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5625 - val_loss: 1.5112\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3477 - val_loss: 1.3309\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1999 - val_loss: 1.2055\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0965 - val_loss: 1.1162\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0225 - val_loss: 1.0511\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9682 - val_loss: 1.0020\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9270 - val_loss: 0.9637\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8949 - val_loss: 0.9337\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8691 - val_loss: 0.9086\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8478 - val_loss: 0.8874\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8296 - val_loss: 0.8692\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8137 - val_loss: 0.8531\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7996 - val_loss: 0.8384\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7869 - val_loss: 0.8248\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7752 - val_loss: 0.8125\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7645 - val_loss: 0.8013\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7545 - val_loss: 0.7907\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7451 - val_loss: 0.7808\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7363 - val_loss: 0.7714\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7280 - val_loss: 0.7624\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7201 - val_loss: 0.7539\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7126 - val_loss: 0.7459\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7055 - val_loss: 0.7383\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6987 - val_loss: 0.7312\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6922 - val_loss: 0.7243\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6861 - val_loss: 0.7178\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6802 - val_loss: 0.7115\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6746 - val_loss: 0.7055\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6691 - val_loss: 0.6998\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6639 - val_loss: 0.6943\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6590 - val_loss: 0.6890\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6542 - val_loss: 0.6840\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6496 - val_loss: 0.6792\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6452 - val_loss: 0.6747\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6409 - val_loss: 0.6702\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6368 - val_loss: 0.6660\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6329 - val_loss: 0.6620\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6291 - val_loss: 0.6580\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6255 - val_loss: 0.6543\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6220 - val_loss: 0.6507\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6186 - val_loss: 0.6473\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6153 - val_loss: 0.6439\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6122 - val_loss: 0.6407\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6091 - val_loss: 0.6377\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6347\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6034 - val_loss: 0.6318\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6006 - val_loss: 0.6291\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.6265\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5954 - val_loss: 0.6240\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5930 - val_loss: 0.6215\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5906 - val_loss: 0.6192\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5883 - val_loss: 0.6169\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5861 - val_loss: 0.6148\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6127\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5819 - val_loss: 0.6107\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5799 - val_loss: 0.6087\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5779 - val_loss: 0.6069\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5761 - val_loss: 0.6051\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5743 - val_loss: 0.6033\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5725 - val_loss: 0.6017\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5708 - val_loss: 0.6001\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5692 - val_loss: 0.5985\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5676 - val_loss: 0.5971\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5660 - val_loss: 0.5956\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.5943\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5631 - val_loss: 0.5929\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5618 - val_loss: 0.5916\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5604 - val_loss: 0.5904\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5591 - val_loss: 0.5893\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5579 - val_loss: 0.5881\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5567 - val_loss: 0.5870\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 0.5860\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5543 - val_loss: 0.5850\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5533 - val_loss: 0.5840\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.5831\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5512 - val_loss: 0.5822\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5502 - val_loss: 0.5814\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5492 - val_loss: 0.5805\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5483 - val_loss: 0.5798\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5474 - val_loss: 0.5790\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5465 - val_loss: 0.5783\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5776\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5448 - val_loss: 0.5770\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5440 - val_loss: 0.5763\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5433 - val_loss: 0.5757\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5425 - val_loss: 0.5751\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5418 - val_loss: 0.5745\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5411 - val_loss: 0.5740\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5405 - val_loss: 0.5735\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5398 - val_loss: 0.5730\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5392 - val_loss: 0.5725\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5386 - val_loss: 0.5720\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 0.5716\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.5712\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5369 - val_loss: 0.5707\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4898\n",
            "[CV]  n_neurons=29, n_hidden=0, learning_rate=0.0004225431080276861, total= 1.4min\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 20.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7161 - val_loss: 0.5764\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.4358\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4180\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4222\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.3947\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3688 - val_loss: 0.3979\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3762\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.3770\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.3869\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3443 - val_loss: 0.3796\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.4319\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3319 - val_loss: 0.3482\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.3770\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3854\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3641\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3449\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3168 - val_loss: 0.3279\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3425\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3100 - val_loss: 0.3535\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3074 - val_loss: 0.3352\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3034 - val_loss: 0.3298\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3600\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3284\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2992 - val_loss: 0.4203\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2977 - val_loss: 0.3301\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3229\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2938 - val_loss: 0.3063\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3086\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2916 - val_loss: 0.3316\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3195\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2961 - val_loss: 0.3355\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2946 - val_loss: 0.3283\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2888 - val_loss: 0.3418\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2888 - val_loss: 0.3134\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.3132\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2853 - val_loss: 0.3107\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2831 - val_loss: 0.3035\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2812 - val_loss: 0.3205\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2801 - val_loss: 0.3137\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2811 - val_loss: 0.3110\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2792 - val_loss: 0.3379\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2790 - val_loss: 0.3108\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2772 - val_loss: 0.3111\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2753 - val_loss: 0.3077\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.2963\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2730 - val_loss: 0.2923\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2708 - val_loss: 0.3006\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2712 - val_loss: 0.3372\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.3116\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2687 - val_loss: 0.2992\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2683 - val_loss: 0.2951\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2669 - val_loss: 0.2911\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2671 - val_loss: 0.3000\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2671 - val_loss: 0.2983\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2667 - val_loss: 0.3353\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2646 - val_loss: 0.3065\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2651 - val_loss: 0.3085\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2634 - val_loss: 0.3187\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2645 - val_loss: 0.3281\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2614 - val_loss: 0.2962\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2615 - val_loss: 0.2986\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2597 - val_loss: 0.2964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f1e7c3d0850>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'learning_rate': [0.000844572050109007,\n",
              "                                                          0.029561677041492953,\n",
              "                                                          0.006487105888488411,\n",
              "                                                          0.00668482622925348,\n",
              "                                                          0.0005300855312043795,\n",
              "                                                          0.005821763147394912,\n",
              "                                                          0.0004000161804620486,\n",
              "                                                          0.000900...\n",
              "                                                          0.010143140076494252,\n",
              "                                                          0.009711066884838545,\n",
              "                                                          0.0007953488722963749,\n",
              "                                                          0.02624780885678252,\n",
              "                                                          0.002626426373198358,\n",
              "                                                          0.0022239507980512745, ...],\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14, 15,\n",
              "                                                      16, 17, 18, 19, 20, 21,\n",
              "                                                      22, 23, 24, 25, 26, 27,\n",
              "                                                      28, 29, 30, ...]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC-wtoyUsU1Z",
        "outputId": "269fdcde-ae58-4eaa-c124-26af7dcc54db"
      },
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.0277582354248053, 'n_hidden': 3, 'n_neurons': 23}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7j08vUTsVHG",
        "outputId": "93c7b213-f7fb-47c1-c437-9b893144aadc"
      },
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3148067394892375"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBpI91EDsd27"
      },
      "source": [
        "model = rnd_search_cv.best_estimator_.model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcVo2cyfsqxD"
      },
      "source": [
        "**랜덤서치의 단점**\n",
        "\n",
        "- 하이퍼파라미터 공간이 크면 시간이 오래 걸린다..\n",
        "- 하이퍼파라미터의 값의 범위를 크게해서 일단 첫 범위를 찾고, 그 중에 좋은 곳에서 또 다시 랜덤서치함.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9KQsGCQs_FC"
      },
      "source": [
        "**더 효율적인 탐색 기법**\n",
        "\n",
        "- 탐색지역이 좋다고 판명될 때 더 탐색을 수행한다!!\n",
        "- 이용할 수 있는 라이브러리들..\n",
        "    - Hyperpot\n",
        "    - Hyperas, kopt, Talos\n",
        "    - 케라스 튜너\n",
        "    - Scikit-Optimize(skopt)\n",
        "    - Spearmint\n",
        "    - Hyperband\n",
        "    - Sklearn-Deap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpuSG_6fYB-x"
      },
      "source": [
        "##10.3.1 은닉층 개수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2N9PCLp-RlV"
      },
      "source": [
        "- 깊어질수록 고수준의 구조를 모델링\n",
        "- 복잡한 문제에서는 심층 신경망이 얕은 신경망보다 **파라미터 효율성**이 좋다\n",
        "    - 아래쪽 은닉층은 저수준의 구조 모델링\n",
        "    - 중간 은닉층은 중간 수준의 구조 모델링\n",
        "    - 위쪽 은닉층과 출력층은 중간의 구조를 연결해 고수준의 구조를 모델링..\n",
        "    - **전이 학습**도 가능.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyA1ilRe-3o9"
      },
      "source": [
        "**정리**\n",
        "\n",
        "- 보통 한두개의 은닉층으로도 문제 잘 해결..\n",
        "- 근데 복잡해지면 과대적합되기 전까지 점진적으로 은닉층의 수를 늘려간다..\n",
        "- 훈련데이터도 엄청나게 필요하다..\n",
        "- 보통은 이전에 비슷한 작업에서 좋은 성능을 낸 네트워크의 일부를 재사용한다.. (**전이 학습**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFQONzbYYB7z"
      },
      "source": [
        "##10.3.2 은닉층의 뉴런 개수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw5TVHS3tZUW"
      },
      "source": [
        "**입력 뉴런, 출력 뉴런의 갯수**\n",
        "\n",
        "- 해당 작업에 필요한 입력과 출력의 형태에 따라 결정됨..\n",
        "- ex) 숫자 mnist : 28*28개의 입력뉴런, 10개의 출력뉴런\n",
        "\n",
        "**은닉층의 구성**\n",
        "\n",
        "- 일반적으로 각 층의 뉴런을 점점 줄여서 깔때기처럼 구성\n",
        "- 첫번째 은닉층을 크게 하는 것이 도움이 됨..\n",
        "- 실전에서는 **필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택하고, 조기종료나 규제기법을 사용하는 것**이 효과적임..\n",
        "- 한 층의 뉴런 수가 너무 적으면 입력의 유용한 특성을 충분히 표현하지 못한다..\n",
        "    - ex) 3D데이터인데 뉴런이 2개라면 다 표현을 못한다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySL8Pts0YBz0"
      },
      "source": [
        "##10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOMSF0FXZSSf"
      },
      "source": [
        "###학습률\n",
        "\n",
        "- 매우 낮은 학습률에서 점점 키워가면서 조정..\n",
        "- 다른 하이퍼파라미터 조정 후 다시 탐색해야함.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4VKZ4O5ZSGz"
      },
      "source": [
        "###옵티마이저\n",
        "\n",
        "- 좋은 옵티마이저를 선택해라.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxrHrNPyZR8k"
      },
      "source": [
        "###배치 크기\n",
        "\n",
        "- 크게 좋다는 쪽도 있고\n",
        "- 32개의 배치 사이즈로 하는게 국룰이라는 쪽도 있다.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45R3rwVBZRyk"
      },
      "source": [
        "###활성화 함수\n",
        "\n",
        "- 기본값 : Relu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX9pvEghZRoW"
      },
      "source": [
        "###반복 획수\n",
        "\n",
        "- 이건 조정하기 보다는 엄청 크게 한 다음 조기종료하는게 더 이득.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-2k9RVyZRgj"
      },
      "source": [
        "#10.4 연습문제"
      ]
    }
  ]
}